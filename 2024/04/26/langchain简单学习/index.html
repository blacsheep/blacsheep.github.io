<!DOCTYPE html>
<html lang=en>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5" />
    <meta name="description" content="中文文档: LangChain 官方都是用的openai的模型,但是免费资源我已经用完了,这里就用免费的llama. import 123456from langchain_community.llms import Ollamafrom langchain_community.chat_models.ollama import ChatOllama# llmllm &#x3D; Ollama(model&#x3D;">
<meta property="og:type" content="article">
<meta property="og:title" content="langchain简单学习">
<meta property="og:url" content="http://example.com/2024/04/26/langchain%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/index.html">
<meta property="og:site_name" content="blacsheep&#39;s blog">
<meta property="og:description" content="中文文档: LangChain 官方都是用的openai的模型,但是免费资源我已经用完了,这里就用免费的llama. import 123456from langchain_community.llms import Ollamafrom langchain_community.chat_models.ollama import ChatOllama# llmllm &#x3D; Ollama(model&#x3D;">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2024/04/26/langchain%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/message_type.png">
<meta property="article:published_time" content="2024-04-26T14:01:43.000Z">
<meta property="article:modified_time" content="2024-04-26T21:04:44.348Z">
<meta property="article:author" content="blacsheep">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2024/04/26/langchain%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/message_type.png">
    
    
      
        
          <link rel="shortcut icon" href="/images/favicon.ico">
        
      
      
        
          <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
        
      
      
        
          <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
        
      
    
    <!-- title -->
    <title>langchain简单学习</title>
    <!-- async scripts -->
    <!-- Google Analytics -->


    <!-- Umami Analytics -->


    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
    <!-- rss -->
    
    
	<!-- mathjax -->
	
		<script type="text/x-mathjax-config">
		  MathJax.Hub.Config({
			tex2jax: {
			  skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
			  inlineMath: [['$','$']]
			}
		  });
		</script>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>
	
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#" aria-label="Menu"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#" aria-label="Menu"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" aria-label="Top" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fa-solid fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     --><!--
       --><li><a href="/categories/">Category</a></li><!--
     --><!--
       --><li><a href="/search/">Search</a></li><!--
     -->
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" aria-label="Previous post" href="/2024/04/27/langchain%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0(2)-chatHistory/"><i class="fa-solid fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" aria-label="Next post" href="/2024/04/25/Llama%E5%AD%A6%E4%B9%A0%E4%BB%A5%E5%8F%8A%E5%AF%B9%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"><i class="fa-solid fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" aria-label="Back to top" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" aria-label="Share post" href="#"><i class="fa-solid fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://example.com/2024/04/26/langchain%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://example.com/2024/04/26/langchain%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/&text=langchain简单学习"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://example.com/2024/04/26/langchain%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/&title=langchain简单学习"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://example.com/2024/04/26/langchain%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/&is_video=false&description=langchain简单学习"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=langchain简单学习&body=Check out this article: http://example.com/2024/04/26/langchain%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/"><i class="fa-solid fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://example.com/2024/04/26/langchain%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/&title=langchain简单学习"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://example.com/2024/04/26/langchain%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/&title=langchain简单学习"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://example.com/2024/04/26/langchain%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/&title=langchain简单学习"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://example.com/2024/04/26/langchain%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/&title=langchain简单学习"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://example.com/2024/04/26/langchain%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/&name=langchain简单学习&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://example.com/2024/04/26/langchain%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/&t=langchain简单学习"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    
    
      <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#import"><span class="toc-number">1.</span> <span class="toc-text">import</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#prompt"><span class="toc-number">2.</span> <span class="toc-text">prompt</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#message-type"><span class="toc-number">3.</span> <span class="toc-text">Message type</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#parser"><span class="toc-number">4.</span> <span class="toc-text">parser</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#chain"><span class="toc-number">5.</span> <span class="toc-text">Chain</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lcel"><span class="toc-number">6.</span> <span class="toc-text">LCEL</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#rag%E5%AE%9E%E4%BE%8B"><span class="toc-number">6.1.</span> <span class="toc-text">RAG实例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#interface"><span class="toc-number">6.2.</span> <span class="toc-text">Interface</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#schema"><span class="toc-number">6.2.1.</span> <span class="toc-text">schema</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#stream"><span class="toc-number">6.2.2.</span> <span class="toc-text">stream</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#invoke-batch"><span class="toc-number">6.2.3.</span> <span class="toc-text">invoke &amp; batch</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BC%82%E6%AD%A5"><span class="toc-number">6.2.4.</span> <span class="toc-text">异步</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A2%98%E5%A4%96%E8%AF%9D"><span class="toc-number">7.</span> <span class="toc-text">题外话</span></a></li></ol>
      </div>
    
  </span>
</div>

    
    <div class="content index py4 ">
        
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle p-name" itemprop="name headline">
        langchain简单学习
    </h1>



    <div class="meta">
      <span class="author p-author h-card" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span class="p-name" itemprop="name">blacsheep</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2024-04-26T14:01:43.000Z" class="dt-published" itemprop="datePublished">2024-04-26</time>
        
      
    </div>


      
    <div class="article-category">
        <i class="fa-solid fa-archive"></i>
        <a class="category-link" href="/categories/ML-NLP/">ML NLP</a>
    </div>


      

    </div>
  </header>
  

  <div class="content e-content" itemprop="articleBody">
    <p>中文文档: <a target="_blank" rel="noopener" href="https://python.langchain.com.cn/docs/modules/memory/types/">LangChain</a></p>
<p>官方都是用的openai的模型,但是免费资源我已经用完了,这里就用免费的llama.</p>
<h2 id="import">import</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_community.llms <span class="keyword">import</span> Ollama</span><br><span class="line"><span class="keyword">from</span> langchain_community.chat_models.ollama <span class="keyword">import</span> ChatOllama</span><br><span class="line"><span class="comment"># llm</span></span><br><span class="line">llm = Ollama(model=<span class="string">&quot;llama3&quot;</span>, keep_alive=-<span class="number">1</span>)</span><br><span class="line"><span class="comment"># chat model</span></span><br><span class="line">chatmodel = ChatOllama(model=<span class="string">&#x27;llama3&#x27;</span>, keep_alive=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p><code>keep_alive=-1</code>可以保证模型总是在内存载入, 方便学习使用, 环境方面用的也是notebook, 块执行方便不少.</p>
<h2 id="prompt">prompt</h2>
<p>prompt将输入从dictionary读入template,本质format</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"></span><br><span class="line">prompt = PromptTemplate.from_template(<span class="string">&quot;What is a good name for a company that makes &#123;product&#125;?&quot;</span>)</span><br><span class="line">prompt.<span class="built_in">format</span>(product=<span class="string">&quot;colorful socks&quot;</span>)</span><br><span class="line"><span class="comment"># &#x27;What is a good name for a company that makes colorful socks?&#x27;</span></span><br></pre></td></tr></table></figure>
<h2 id="message-type">Message type</h2>
<p>首先几种类型</p>
<p><img src="message_type.png" /></p>
<ul>
<li>HumanMessage: 来自人类/用户的ChatMessage。</li>
<li>AIMessage: 来自AI/助手的ChatMessage。</li>
<li>SystemMessage: 来自系统的ChatMessage。</li>
<li>FunctionMessage: 来自函数调用的ChatMessage。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.prompts.chat <span class="keyword">import</span> (</span><br><span class="line">    ChatPromptTemplate,</span><br><span class="line">    SystemMessagePromptTemplate,</span><br><span class="line">    HumanMessagePromptTemplate,</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 系统全局设定</span></span><br><span class="line">template = <span class="string">&quot;You are a helpful assistant that translates &#123;input_language&#125; to &#123;output_language&#125;.&quot;</span></span><br><span class="line">system_message_prompt = SystemMessagePromptTemplate.from_template(template)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用户输入</span></span><br><span class="line">human_template = <span class="string">&quot;&#123;text&#125;&quot;</span></span><br><span class="line">human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)</span><br><span class="line"></span><br><span class="line"><span class="comment"># chat构建</span></span><br><span class="line">chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])</span><br><span class="line"></span><br><span class="line">chat_prompt.format_messages(input_language=<span class="string">&quot;English&quot;</span>, output_language=<span class="string">&quot;Chinese&quot;</span>, text=<span class="string">&quot;I love programming.&quot;</span>)</span><br><span class="line"><span class="comment"># [SystemMessage(content=&#x27;You are a helpful assistant that translates English to Chinese.&#x27;), HumanMessage(content=&#x27;I love programming.&#x27;)]</span></span><br></pre></td></tr></table></figure>
<h2 id="parser">parser</h2>
<p>负责输出解析</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.schema <span class="keyword">import</span> BaseOutputParser</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CommaSeparatedListOutputParser</span>(<span class="title class_ inherited__">BaseOutputParser</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Parse the output of an LLM call to a comma-separated list.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, text: <span class="built_in">str</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Parse the output of an LLM call.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> text.strip().split(<span class="string">&quot;, &quot;</span>)</span><br><span class="line"></span><br><span class="line">CommaSeparatedListOutputParser().parse(<span class="string">&quot;hi, bye&quot;</span>)</span><br><span class="line"><span class="comment"># [&#x27;hi&#x27;, &#x27;bye&#x27;]</span></span><br></pre></td></tr></table></figure>
<p>文档前面介绍的parser都非常简单, 几乎都是basemodel, 但其实parser提供的功能是一方面是输出解析, 另一方面也可以看作下一个pipline输入的preprocessing.</p>
<h2 id="chain">Chain</h2>
<p>模块连接</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> LLMChain</span><br><span class="line"><span class="comment"># 系统全局设定</span></span><br><span class="line"><span class="comment"># template = &quot;You no nothing about &#123;subject&#125; and have no common sense.&quot;</span></span><br><span class="line">template = <span class="string">&quot;You are an expert in &#123;subject&#125;.&quot;</span></span><br><span class="line">system_message_prompt = SystemMessagePromptTemplate.from_template(template)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用户输入</span></span><br><span class="line">human_template = <span class="string">&quot;&#123;text&#125;&quot;</span></span><br><span class="line">human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)</span><br><span class="line"></span><br><span class="line"><span class="comment"># chat构建</span></span><br><span class="line">chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])</span><br><span class="line">chain = LLMChain(</span><br><span class="line">    llm = llm,</span><br><span class="line">    prompt=chat_prompt,</span><br><span class="line">    output_parser=CommaSeparatedListOutputParser()</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">chain.invoke(&#123;<span class="string">&#x27;subject&#x27;</span>:<span class="string">&#x27;math&#x27;</span>, <span class="string">&#x27;text&#x27;</span>:<span class="string">&#x27;try to predict the next 5 numbers: 1, 1, 2, 3, 5&#x27;</span>&#125;)</span><br><span class="line"><span class="comment"># &#123;&#x27;subject&#x27;: &#x27;math&#x27;,</span></span><br><span class="line"><span class="comment">#  &#x27;text&#x27;: [&#x27;A classic sequence!\n\nThis appears to be the Fibonacci sequence&#x27;,</span></span><br><span class="line"><span class="comment">#   &#x27;where each number is the sum of the two preceding ones:\n\n1&#x27;,</span></span><br><span class="line"><span class="comment">#   &#x27;1&#x27;,</span></span><br><span class="line"><span class="comment">#   &#x27;2&#x27;,</span></span><br><span class="line"><span class="comment">#   &#x27;3&#x27;,</span></span><br><span class="line"><span class="comment">#   &#x27;5&#x27;,</span></span><br><span class="line"><span class="comment">#   &quot;...\n\nIf that&#x27;s correct&quot;,</span></span><br><span class="line"><span class="comment">#   &#x27;the next five numbers would be:\n\n8&#x27;,</span></span><br><span class="line"><span class="comment">#   &#x27;13&#x27;,</span></span><br><span class="line"><span class="comment">#   &#x27;21&#x27;,</span></span><br><span class="line"><span class="comment">#   &#x27;34&#x27;,</span></span><br><span class="line"><span class="comment">#   &#x27;55\n\nAm I right?&#x27;]&#125;</span></span><br></pre></td></tr></table></figure>
<h2 id="lcel">LCEL</h2>
<p>Langchain表达式, 官方描述的优势</p>
<ul>
<li>流式支持</li>
<li>异步</li>
<li>并行处理</li>
<li>重试回退</li>
<li>中间结果访问</li>
<li>输入输出模式</li>
<li>LangSmith跟踪以提供可调试性</li>
<li>无缝LangServe集成</li>
</ul>
<p>目前我只读到了并行.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> StrOutputParser</span><br><span class="line">prompt = ChatPromptTemplate.from_template(<span class="string">&#x27;tell me a short joke about &#123;topic&#125;&#x27;</span>)</span><br><span class="line">output_parser = StrOutputParser()</span><br><span class="line">chain = prompt | llm | output_parser</span><br><span class="line">chain.invoke(&#123;<span class="string">&#x27;topic&#x27;</span>:<span class="string">&#x27;large language model&#x27;</span>&#125;)</span><br></pre></td></tr></table></figure>
<p>这里的管道符负责的是连接组件</p>
<p>那么模型发生了什么呢?</p>
<ol type="1">
<li>首先Prompt接受输入生成PromptValue</li>
<li>chatModel接收到PromptValue之后生成ChatMessage(如果是LLM的话输出为str)</li>
<li>最后ChatMessage丢入parser负责最终解析,最后输出</li>
</ol>
<h3 id="rag实例">RAG实例</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_community.vectorstores <span class="keyword">import</span> DocArrayInMemorySearch</span><br><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> StrOutputParser</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_core.runnables <span class="keyword">import</span> RunnableParallel, RunnablePassthrough</span><br><span class="line"><span class="keyword">from</span> langchain_community.chat_models.ollama <span class="keyword">import</span> ChatOllama</span><br><span class="line"><span class="keyword">from</span> langchain_community.embeddings.ollama <span class="keyword">import</span> OllamaEmbeddings</span><br><span class="line"></span><br><span class="line">vectorstore = DocArrayInMemorySearch.from_texts(</span><br><span class="line">    [<span class="string">&#x27;harrison worked at kensho&#x27;</span>, <span class="string">&#x27;bears like to eat honey&#x27;</span>],</span><br><span class="line">    embedding=OllamaEmbeddings(),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">retriever = vectorstore.as_retriever()</span><br><span class="line">template = <span class="string">&#x27;&#x27;&#x27;Answer the question based only on the following context:</span></span><br><span class="line"><span class="string">&#123;context&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Question: &#123;question&#125;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">prompt = ChatPromptTemplate.from_template(template)</span><br><span class="line"><span class="comment"># chatmodel = ChatOllama(model=&#x27;llama3&#x27;, keep_alive=-1)</span></span><br><span class="line"></span><br><span class="line">output_parser = StrOutputParser()</span><br><span class="line">setup_and_retrieval = RunnableParallel(</span><br><span class="line">    &#123;<span class="string">&#x27;context&#x27;</span>: retriever, <span class="string">&#x27;question&#x27;</span>: RunnablePassthrough()&#125;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">chain = setup_and_retrieval | prompt | chatmodel | output_parser</span><br><span class="line">chain.invoke(<span class="string">&#x27;what did bear eat?&#x27;</span>)</span><br><span class="line"><span class="comment"># &#x27;According to the provided context, bears like to eat honey.&#x27;</span></span><br></pre></td></tr></table></figure>
<p>上述模版接受context和question.</p>
<ol type="1">
<li>首先创造RunnableParallel从文档检索context, 然后RunnablePassthrough输入传入到question</li>
<li>上述步骤构成的字典传入prompt构成promptValue</li>
<li>chatmodel接收到promptValue生成chatMessage</li>
<li>parser接受Message做解析然后输出</li>
</ol>
<h3 id="interface">Interface</h3>
<h4 id="schema">schema</h4>
<p>schema用于查看输入输出模式</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">prompt = ChatPromptTemplate.from_template(<span class="string">&quot;tell me a joke about &#123;topic&#125;&quot;</span>)</span><br><span class="line">chain = prompt | chatmodel</span><br><span class="line">chain.input_schema.schema(), chain.output_schema.schema()</span><br></pre></td></tr></table></figure>
<h4 id="stream">stream</h4>
<p>流式输出</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> s <span class="keyword">in</span> chain.stream(&#123;<span class="string">&quot;topic&quot;</span>: <span class="string">&quot;bears&quot;</span>&#125;):</span><br><span class="line">    <span class="built_in">print</span>(s.content, end=<span class="string">&quot;&quot;</span>, flush=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h4 id="invoke-batch">invoke &amp; batch</h4>
<p>invoke输入执行, batch输入列表执行</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">chain.invoke(&#123;<span class="string">&quot;topic&quot;</span>: <span class="string">&quot;bears&quot;</span>&#125;)</span><br><span class="line"><span class="comment"># AIMessage(content=&#x27;Why did the bear go to the doctor?\n\nBecause it had a grizzly cough!\n\nHope that made you roar with laughter!&#x27;, response_metadata=&#123;&#x27;model&#x27;: &#x27;llama3&#x27;, &#x27;created_at&#x27;: &#x27;2024-04-26T18:59:12.682597827Z&#x27;, &#x27;message&#x27;: &#123;&#x27;role&#x27;: &#x27;assistant&#x27;, &#x27;content&#x27;: &#x27;&#x27;&#125;, &#x27;done&#x27;: True, &#x27;total_duration&#x27;: 2376927414, &#x27;load_duration&#x27;: 780076, &#x27;prompt_eval_duration&#x27;: 104313000, &#x27;eval_count&#x27;: 26, &#x27;eval_duration&#x27;: 2269974000&#125;, id=&#x27;run-1da506c7-4321-43b3-9a20-73e378bb5d53-0&#x27;)</span></span><br><span class="line">chain.batch([&#123;<span class="string">&quot;topic&quot;</span>: <span class="string">&quot;bears&quot;</span>&#125;, &#123;<span class="string">&quot;topic&quot;</span>: <span class="string">&quot;cats&quot;</span>&#125;])</span><br><span class="line"><span class="comment"># [AIMessage(content=&quot;Here&#x27;s one:\n\nWhy did the bear go to the doctor?\n\nBecause it had a grizzly cough!\n\nHope that made you roar with laughter!&quot;, response_metadata=&#123;&#x27;model&#x27;: &#x27;llama3&#x27;, &#x27;created_at&#x27;: &#x27;2024-04-26T18:59:27.384268553Z&#x27;, &#x27;message&#x27;: &#123;&#x27;role&#x27;: &#x27;assistant&#x27;, &#x27;content&#x27;: &#x27;&#x27;&#125;, &#x27;done&#x27;: True, &#x27;total_duration&#x27;: 3058382240, &#x27;load_duration&#x27;: 446359, &#x27;prompt_eval_count&#x27;: 6, &#x27;prompt_eval_duration&#x27;: 415392000, &#x27;eval_count&#x27;: 30, &#x27;eval_duration&#x27;: 2641467000&#125;, id=&#x27;run-8fcefbc7-d3eb-424f-8328-ff1c4c9461c0-0&#x27;),</span></span><br><span class="line"><span class="comment"># AIMessage(content=&#x27;Why did the cat join a band?\n\nBecause it wanted to be the purr-cussionist!\n\nMeow-velous, right?&#x27;, response_metadata=&#123;&#x27;model&#x27;: &#x27;llama3&#x27;, &#x27;created_at&#x27;: &#x27;2024-04-26T18:59:24.325741194Z&#x27;, &#x27;message&#x27;: &#123;&#x27;role&#x27;: &#x27;assistant&#x27;, &#x27;content&#x27;: &#x27;&#x27;&#125;, &#x27;done&#x27;: True, &#x27;total_duration&#x27;: 2914778748, &#x27;load_duration&#x27;: 1199486, &#x27;prompt_eval_count&#x27;: 6, &#x27;prompt_eval_duration&#x27;: 425677000, &#x27;eval_count&#x27;: 29, &#x27;eval_duration&#x27;: 2484935000&#125;, id=&#x27;run-cd7e0e28-818e-4b4b-a5d6-60f71b815bf9-0&#x27;)]</span></span><br></pre></td></tr></table></figure>
<h4 id="异步">异步</h4>
<p>上述方法都支持异步:</p>
<ul>
<li>astream: 异步流式返回响应的块</li>
<li>ainvoke: 异步在输入上调用链</li>
<li>abatch: 异步在输入列表上调用链</li>
<li>astream_log: 异步流式返回中间步骤，以及最终响应</li>
<li>astream_events: beta 异步流式返回链中发生的事件（在 langchain-core 0.1.14 中引入）</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">for</span> s <span class="keyword">in</span> chain.astream(&#123;<span class="string">&quot;topic&quot;</span>: <span class="string">&quot;bears&quot;</span>&#125;):</span><br><span class="line">    <span class="built_in">print</span>(s.content, end=<span class="string">&quot;&quot;</span>, flush=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h2 id="题外话">题外话</h2>
<p>看到这里大概已经明白langchain是干啥的了, 想了一下感觉这种用户可以随意输入框架肯定也会有安全问题, 比如如何保证输入是安全的呢. 然后就看到有文章已经讲过了: <a target="_blank" rel="noopener" href="https://www.secrss.com/articles/59635">深入剖析大模型安全问题：Langchain框架的隐藏风险</a>.</p>
<p>CVE-2023-29374: LLMMathChain任意代码执行漏洞. 所以说开发中还是要保留一些安全意识, 尤其是有用户可控行为的时候.</p>
<p>这里只是langchain的最基础的部分但也是最核心的部分, 后续还会继续看Langchain的剩下一部分文档.</p>

  </div>
</article>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
        
          <li><a href="/">Home</a></li>
        
          <li><a href="/about/">About</a></li>
        
          <li><a href="/archives/">Writing</a></li>
        
          <li><a href="/categories/">Category</a></li>
        
          <li><a href="/search/">Search</a></li>
        
      </ul>
    </div>

    
    
      <div id="toc-footer" style="display: none">
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#import"><span class="toc-number">1.</span> <span class="toc-text">import</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#prompt"><span class="toc-number">2.</span> <span class="toc-text">prompt</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#message-type"><span class="toc-number">3.</span> <span class="toc-text">Message type</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#parser"><span class="toc-number">4.</span> <span class="toc-text">parser</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#chain"><span class="toc-number">5.</span> <span class="toc-text">Chain</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lcel"><span class="toc-number">6.</span> <span class="toc-text">LCEL</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#rag%E5%AE%9E%E4%BE%8B"><span class="toc-number">6.1.</span> <span class="toc-text">RAG实例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#interface"><span class="toc-number">6.2.</span> <span class="toc-text">Interface</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#schema"><span class="toc-number">6.2.1.</span> <span class="toc-text">schema</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#stream"><span class="toc-number">6.2.2.</span> <span class="toc-text">stream</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#invoke-batch"><span class="toc-number">6.2.3.</span> <span class="toc-text">invoke &amp; batch</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BC%82%E6%AD%A5"><span class="toc-number">6.2.4.</span> <span class="toc-text">异步</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A2%98%E5%A4%96%E8%AF%9D"><span class="toc-number">7.</span> <span class="toc-text">题外话</span></a></li></ol>
      </div>
    

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://example.com/2024/04/26/langchain%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://example.com/2024/04/26/langchain%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/&text=langchain简单学习"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://example.com/2024/04/26/langchain%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/&title=langchain简单学习"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://example.com/2024/04/26/langchain%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/&is_video=false&description=langchain简单学习"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=langchain简单学习&body=Check out this article: http://example.com/2024/04/26/langchain%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/"><i class="fa-solid fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://example.com/2024/04/26/langchain%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/&title=langchain简单学习"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://example.com/2024/04/26/langchain%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/&title=langchain简单学习"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://example.com/2024/04/26/langchain%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/&title=langchain简单学习"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://example.com/2024/04/26/langchain%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/&title=langchain简单学习"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://example.com/2024/04/26/langchain%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/&name=langchain简单学习&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://example.com/2024/04/26/langchain%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0/&t=langchain简单学习"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fa-solid fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        
          <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fa-solid fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fa-solid fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2016-2024
    blacsheep
  </div>
  <div class="footer-right">
    <nav>
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     --><!--
       --><li><a href="/categories/">Category</a></li><!--
     --><!--
       --><li><a href="/search/">Search</a></li><!--
     -->
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->



  <link rel="preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" crossorigin="anonymous" onload="this.onload=null;this.rel='stylesheet'"/>


    <!-- jquery -->

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" crossorigin="anonymous"></script>




<!-- clipboard -->

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.7/clipboard.min.js" crossorigin="anonymous"></script>
  
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="fa-regular fa-clone"></i>';
    btn += '</span>';
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Baidu Analytics -->

<!-- Cloudflare Analytics -->

<!-- Disqus Comments -->

<!-- utterances Comments -->

</body>
</html>
