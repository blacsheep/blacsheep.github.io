<!DOCTYPE html>
<html lang=en>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5" />
    <meta name="description" content="前言 前段时间一直在看NLP相关, 不过最后好像发现没有进入工业界程度的话所有下游任务都是deberta就直接结束了的, kaggle上面LGBM+DeBERTa的方案在最新的竞赛也是首选, 我尝试加了grammar check并做了简单feature engineering但效率其实还是没有提升多少, 再往后可能就只能等比赛结束看top1用的是什么trick了. 而另一方面LDM在调了不少东西之">
<meta property="og:type" content="article">
<meta property="og:title" content="工业化推荐系统相关">
<meta property="og:url" content="http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/index.html">
<meta property="og:site_name" content="blacsheep&#39;s blog">
<meta property="og:description" content="前言 前段时间一直在看NLP相关, 不过最后好像发现没有进入工业界程度的话所有下游任务都是deberta就直接结束了的, kaggle上面LGBM+DeBERTa的方案在最新的竞赛也是首选, 我尝试加了grammar check并做了简单feature engineering但效率其实还是没有提升多少, 再往后可能就只能等比赛结束看top1用的是什么trick了. 而另一方面LDM在调了不少东西之">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/%E9%9A%8F%E6%9C%BA%E5%88%86%E6%A1%B6.png">
<meta property="og:image" content="http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/%E4%BA%92%E6%96%A5%E6%AD%A3%E4%BA%A4.png">
<meta property="og:image" content="http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/holdout.png">
<meta property="og:image" content="http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/%E5%8F%8D%E8%BD%AC%E5%AE%9E%E9%AA%8C.png">
<meta property="og:image" content="http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/userCF.png">
<meta property="og:image" content="http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/two_tower.png">
<meta property="og:image" content="http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/neg_sample.png">
<meta property="og:image" content="http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/two_tower_mainloss.png">
<meta property="og:image" content="http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/twotower_mainloss_withbias.png">
<meta property="og:image" content="http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/twotower_self.png">
<meta property="og:image" content="http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/two_tower_loss.png">
<meta property="og:image" content="http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/x2abc.png">
<meta property="og:image" content="http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/non_recall.png">
<meta property="og:image" content="http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/bloomfilter.png">
<meta property="og:image" content="http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/bloomfilter_data.png">
<meta property="article:published_time" content="2024-05-13T08:16:55.000Z">
<meta property="article:modified_time" content="2024-05-17T12:44:15.954Z">
<meta property="article:author" content="blacsheep">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/%E9%9A%8F%E6%9C%BA%E5%88%86%E6%A1%B6.png">
    
    
      
        
          <link rel="shortcut icon" href="/images/favicon.ico">
        
      
      
        
          <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
        
      
      
        
          <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
        
      
    
    <!-- title -->
    <title>工业化推荐系统相关</title>
    <!-- async scripts -->
    <!-- Google Analytics -->


    <!-- Umami Analytics -->


    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
    <!-- rss -->
    
    
	<!-- mathjax -->
	
		<script type="text/x-mathjax-config">
		  MathJax.Hub.Config({
			tex2jax: {
			  skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
			  inlineMath: [['$','$']]
			}
		  });
		</script>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>
	
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#" aria-label="Menu"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#" aria-label="Menu"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" aria-label="Top" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fa-solid fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     --><!--
       --><li><a href="/categories/">Category</a></li><!--
     --><!--
       --><li><a href="/search/">Search</a></li><!--
     -->
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" aria-label="Previous post" href="/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/"><i class="fa-solid fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" aria-label="Next post" href="/2024/05/08/Norm%E7%9B%B8%E5%85%B3/"><i class="fa-solid fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" aria-label="Back to top" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" aria-label="Share post" href="#"><i class="fa-solid fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/&text=工业化推荐系统相关"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/&title=工业化推荐系统相关"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/&is_video=false&description=工业化推荐系统相关"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=工业化推荐系统相关&body=Check out this article: http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/"><i class="fa-solid fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/&title=工业化推荐系统相关"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/&title=工业化推荐系统相关"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/&title=工业化推荐系统相关"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/&title=工业化推荐系统相关"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/&name=工业化推荐系统相关&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/&t=工业化推荐系统相关"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    
    
      <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#tutorial-reference"><span class="toc-number">2.</span> <span class="toc-text">Tutorial &amp; Reference</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#background"><span class="toc-number">3.</span> <span class="toc-text">Background</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#data%E7%9B%B8%E5%85%B3"><span class="toc-number">3.1.</span> <span class="toc-text">Data相关</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8C%87%E6%A0%87%E7%9F%AD%E6%9C%9F%E6%8C%87%E6%A0%87"><span class="toc-number">3.2.</span> <span class="toc-text">指标(短期指标)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8C%97%E6%9E%81%E6%98%9F%E6%8C%87%E6%A0%87%E9%95%BF%E6%9C%9F%E6%8C%87%E6%A0%87"><span class="toc-number">3.3.</span> <span class="toc-text">北极星指标(长期指标)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E6%B5%81%E7%A8%8B"><span class="toc-number">3.4.</span> <span class="toc-text">实验流程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#ab%E6%B5%8B%E8%AF%95"><span class="toc-number">3.4.1.</span> <span class="toc-text">AB测试</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E5%88%86%E6%A1%B6"><span class="toc-number">3.4.1.1.</span> <span class="toc-text">随机分桶</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E5%B1%82%E5%AE%9E%E9%AA%8C"><span class="toc-number">3.4.1.2.</span> <span class="toc-text">分层实验</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#holdout%E6%9C%BA%E5%88%B6"><span class="toc-number">3.4.1.3.</span> <span class="toc-text">Holdout机制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%8D%E8%BD%AC%E5%AE%9E%E9%AA%8C"><span class="toc-number">3.4.1.4.</span> <span class="toc-text">反转实验</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#pipline"><span class="toc-number">4.</span> <span class="toc-text">Pipline</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%AC%E5%9B%9E"><span class="toc-number">5.</span> <span class="toc-text">召回</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#itemcf"><span class="toc-number">5.1.</span> <span class="toc-text">itemCF</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#similarity"><span class="toc-number">5.1.1.</span> <span class="toc-text">similarity</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cosine-similarity"><span class="toc-number">5.1.2.</span> <span class="toc-text">cosine similarity</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B7%A5%E4%B8%9A%E5%8C%96%E4%BD%BF%E7%94%A8"><span class="toc-number">5.1.3.</span> <span class="toc-text">工业化使用</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#swing"><span class="toc-number">5.2.</span> <span class="toc-text">Swing</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#usercf"><span class="toc-number">5.3.</span> <span class="toc-text">userCF</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9F%A9%E9%98%B5%E8%A1%A5%E5%85%85not-working"><span class="toc-number">5.4.</span> <span class="toc-text">矩阵补充(not working)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B7%A5%E4%B8%9A%E7%95%8C%E5%81%9A%E6%B3%95%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%A4%84%E7%90%86"><span class="toc-number">5.4.1.</span> <span class="toc-text">工业界做法(复杂度处理)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%8C%E5%A1%94%E6%A8%A1%E5%9E%8B"><span class="toc-number">5.5.</span> <span class="toc-text">双塔模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E6%9E%84"><span class="toc-number">5.5.1.</span> <span class="toc-text">结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83"><span class="toc-number">5.5.2.</span> <span class="toc-text">训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AD%A3%E8%B4%9F%E6%A0%B7%E6%9C%AC"><span class="toc-number">5.5.3.</span> <span class="toc-text">正负样本</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BA%BF%E4%B8%8A%E5%8F%AC%E5%9B%9E"><span class="toc-number">5.5.4.</span> <span class="toc-text">线上召回</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%A8%E9%87%8F%E6%9B%B4%E6%96%B0%E5%92%8C%E5%A2%9E%E9%87%8F%E6%9B%B4%E6%96%B0"><span class="toc-number">5.5.5.</span> <span class="toc-text">全量更新和增量更新</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="toc-number">5.5.6.</span> <span class="toc-text">自监督学习</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#deep-retrieval%E5%AD%97%E8%8A%82"><span class="toc-number">5.6.</span> <span class="toc-text">Deep Retrieval(字节)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%A8%E6%88%B7%E5%AF%B9%E8%B7%AF%E5%BE%84%E7%9A%84%E5%85%B4%E8%B6%A3"><span class="toc-number">5.6.1.</span> <span class="toc-text">用户对路径的兴趣</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%A8%E6%88%B7%E5%AF%B9%E8%B7%AF%E5%BE%84%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%96%B9%E5%BC%8F"><span class="toc-number">5.6.2.</span> <span class="toc-text">用户对路径的学习方式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0%E7%89%A9%E5%93%81%E8%A1%A8%E5%BE%81"><span class="toc-number">5.6.3.</span> <span class="toc-text">学习物品表征</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B6%E4%BB%96%E5%8F%AC%E5%9B%9E%E9%80%9A%E9%81%93"><span class="toc-number">5.7.</span> <span class="toc-text">其他召回通道</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%8D%E9%80%82%E5%90%88%E5%8F%AC%E5%9B%9E%E7%9A%84%E6%A8%A1%E5%9E%8B"><span class="toc-number">5.8.</span> <span class="toc-text">不适合召回的模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9B%9D%E5%85%89%E8%BF%87%E6%BB%A4"><span class="toc-number">5.9.</span> <span class="toc-text">曝光过滤</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#bloom-filter"><span class="toc-number">5.9.1.</span> <span class="toc-text">bloom filter</span></a></li></ol></li></ol></li></ol>
      </div>
    
  </span>
</div>

    
    <div class="content index py4 ">
        
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle p-name" itemprop="name headline">
        工业化推荐系统相关
    </h1>



    <div class="meta">
      <span class="author p-author h-card" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span class="p-name" itemprop="name">blacsheep</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2024-05-13T08:16:55.000Z" class="dt-published" itemprop="datePublished">2024-05-13</time>
        
      
    </div>


      
    <div class="article-category">
        <i class="fa-solid fa-archive"></i>
        <a class="category-link" href="/categories/ML-Recommender-System/">ML Recommender System</a>
    </div>


      

    </div>
  </header>
  

  <div class="content e-content" itemprop="articleBody">
    <h1 id="前言">前言</h1>
<p>前段时间一直在看NLP相关, 不过最后好像发现没有进入工业界程度的话所有下游任务都是deberta就直接结束了的, kaggle上面LGBM+DeBERTa的方案在最新的竞赛也是首选, 我尝试加了grammar check并做了简单feature engineering但效率其实还是没有提升多少, 再往后可能就只能等比赛结束看top1用的是什么trick了.</p>
<p>而另一方面LDM在调了不少东西之后VQ终于跑通了, 但是第二部分却比我想象的复杂不少, CrossAttention的点和UNet和ddpi结合的点有点复杂, 不过本身也是一个side project, 空下来了再继续就行.</p>
<p>这段时间想要看看Recommender System相关,顺着毕业设计的方向把这个领域摸清楚, 感觉自己基础就打的差不多了. 再后续就得补一补MLFlow和AWS这种工业相关的东西.</p>
<h1 id="tutorial-reference">Tutorial &amp; Reference</h1>
<p>比较系统的教学在youtube也有视频: <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=nT_74f3E7c4">推荐系统公开课——8小时完整版，讲解工业界真实的推荐系统</a></p>
<h1 id="background">Background</h1>
<h2 id="data相关">Data相关</h2>
<p>与推荐系统相关的信号多与产品有关, 举个例子: b站视频发布过后你看到一些相关视频(Impression), 你可能会点进去(Click), 你可能会看完视频(在小红书的示例中被标为ScrollToEnd), 然后点赞收藏投币评论等.</p>
<p>这些都是相关信号, 表示用户对相关内容是否感兴趣, 它们可以转化成训练数据, 对模型有帮助.</p>
<h2 id="指标短期指标">指标(短期指标)</h2>
<ul>
<li>点击率(CTR): 点击次数 / 曝光次数<br />
</li>
<li>点赞率: 点赞次数 / 点击次数<br />
</li>
<li>收藏率: 收藏次数 / 点击次数<br />
</li>
<li>转发率: 转发次数 / 点击次数<br />
</li>
<li>阅读完成率: 完成阅读次数 / 点击次数 * <span class="math inline">\(f\)</span>(笔记长度)</li>
</ul>
<p>需要注意阅读完成率最后需要对笔记长度做归一化保证对长内容公平.</p>
<p>注意: 指标只是显示用户短期是否感兴趣, 与之对比, 内容多样性如果做得好, 用户可能更具有粘性.</p>
<h2 id="北极星指标长期指标">北极星指标(长期指标)</h2>
<ul>
<li>用户规模: 日活用户数量(DAU), 月活用户数量(MAU)<br />
</li>
<li>消费: 人均使用推荐时长, 人均阅读数量(用户上瘾程度)<br />
</li>
<li>发布: 发布渗透率, 人均发布量.</li>
</ul>
<h2 id="实验流程">实验流程</h2>
<p>离线实验 -&gt; 小流量AB测试 -&gt; 全流量上线</p>
<ul>
<li>离线测试即收集用户过去信息, 在历史数据上面做训练和测试, 此过程没有涉及算法和用户的交互, 也不会对用户产生负面或正面影响<br />
</li>
<li>小流量AB测试: 挑选一部分用户做实验组, 一部分做对照组, 对比两者指标完成度, 判断是否可以全流量上线.<br />
</li>
<li>显著优于旧策略即可以考虑全流量上线.</li>
</ul>
<h3 id="ab测试">AB测试</h3>
<p>举例:</p>
<ul>
<li>召回团队设计了一种GNN召回通道, 离线实验正向, 需要做AB测试来判断对线上指标影响.<br />
</li>
<li>GNN深度可能可以设置<code>&#123;1, 2, 3&#125;</code>, 我们需要AB测试来选参数</li>
</ul>
<h4 id="随机分桶">随机分桶</h4>
<p>将n个用户随机分为b个桶, 每个桶就有 <code>$ \frac&#123;n&#125;&#123;b&#125; $</code> 个用户</p>
<p>用哈希函数将用户ID映射为某区间内的整数, 然后将这些整数均匀分为b个桶. 比如下图选1,2,3做实验组, 4做对照组. 然后统计每个桶的业务指标, 比如DAU, CTR等, 如果某个实验组效果显著, 说明策略有效, 可以推全.</p>
<p><img src="随机分桶.png" /></p>
<h4 id="分层实验">分层实验</h4>
<p>一个产品可能包含很多部门, 大家都需要做AB实验. 假如我们将用户分10个桶, 那么最多只能开9个实验, 显然不够使用.</p>
<p>解决方案是分层实验: <strong>同层互斥, 不同层正交</strong>.</p>
<ul>
<li>召回层作为单独一层, 比如GNN实验占了召回层4个桶, 那么其他召回实验就只能选其他6个桶.<br />
</li>
<li>UI层作为另外一层, 和召回层不同层, 因此还是可以使用全部10个桶.</li>
</ul>
<p>召回层10%的用户打散分到UI层, UI层选一个桶之后只有10% * 10% = 1% 的交集.</p>
<p><img src="互斥正交.png" /></p>
<h4 id="holdout机制">Holdout机制</h4>
<p>业务考核相关, 为了计算某部门对业务指标的整体提升, 我们可以取10%作为holdout桶, 部门所有AB实验使用其余90%用户, 最终考核用90%用户归一化与10%holdout做diff.</p>
<p><img src="holdout.png" /></p>
<p>考核周期结束清除holdout推广实验从90%到100%, 重新划分用户开始下一轮周期.</p>
<h4 id="反转实验">反转实验</h4>
<p>当实验策略取得显著效果, 我们希望推全, 但同时有些指标存在滞后性, 需要长期观测.</p>
<ul>
<li>保留观测好处: 观测到的指标更准确<br />
</li>
<li>尽快推全好处: 腾出桶供其他同层实验使用, 或是基于新策略做后续开发.</li>
</ul>
<p><img src="反转实验.png" /></p>
<p>反转实验解决方法: 新开一层, 留下小部分用户作为反转桶, 其他用户推全新策略.</p>
<p>考核周期结束清除holdout的时候依旧保留反转桶, 只将推全的策略运用到holdout上.</p>
<p>当反转实验完成的时候, 关闭反转实验, 清除反转桶, 真正推广新策略到全部用户.</p>
<h1 id="pipline">Pipline</h1>
<p>推荐系统的Pipline一般分为: 召回 -&gt; 粗排 -&gt; 精排 -&gt; 重排</p>
<ul>
<li>召回通过不同召回通道取数据, 每个通道取几十几百, 目的是将百万级及以上数据过滤到千级.<br />
</li>
<li>粗排: 用简单的机器学习模型打分, 按分数做排序和截断, 将千级数据过滤到百级.<br />
</li>
<li>精排: 还是打分, 不过区别于粗排, 这里需要上模型复杂度, 怎么准确怎么来.<br />
</li>
<li>重排: 依据精排分数和多样性随机抽样, 依据产品策略和多样性需求来重新内部排列精排结果并插入广告之类运营内容.</li>
</ul>
<h1 id="召回">召回</h1>
<p>召回通道: 协同过滤 (Collaborative Filtering), 双塔模型, 关注的作者等.</p>
<h2 id="itemcf">itemCF</h2>
<p>说人话就是依据user对item的喜好程度加上item之间的相似度做推荐.</p>
<ul>
<li>用户喜欢物品1, 且物品1和物品2很相似<br />
</li>
<li>那么用户很可能喜欢物品2</li>
</ul>
<p><span class="math display">\[
\sum_j like(user, item_j) \times sim(item_j, item)
\]</span></p>
<p>其中like表示user对item的喜爱程度, 比如可以用score表示</p>
<h3 id="similarity">similarity</h3>
<p>下面是一个计算相似度的例子</p>
<p><span class="math display">\[
sim(i_1, i_2) = \frac{\left| v \right|}{\sqrt{\left|{w_1}\right|\cdot\left|{w_2}\right|}}
\]</span></p>
<p>其中喜欢物品<code>$ i_1 $</code> 的为<code>$ w_1 $</code>, 喜欢物品 <code>$ i_2 $</code>的为 <code>$ w_2 $</code>, v为 <code>$ w_1 \cap w_2 $</code>. 不过此公式为集合形式,没考虑权重, 只有喜欢或不喜欢.</p>
<h3 id="cosine-similarity">cosine similarity</h3>
<p>也可以选择用cosine similarity</p>
<p><span class="math display">\[
sim(i_1, i_2) = \frac{\sum_{v \in V} like(v, i_1) \cdot like(v, i_2)}{\sqrt{\sum_{u_1 \in w_1}like^2(u_1, i_1)} \cdot {\sqrt{\sum_{u_2 \in  w_2}like^2(u_2, i_2)}}}
\]</span></p>
<p>这里like只可取0或1的时候就是上面的公式.</p>
<h3 id="工业化使用">工业化使用</h3>
<p>由于两两计算物品相似度是非常耗时的工作, 所以工业界采用离线计算的方式.</p>
<p>离线:</p>
<ul>
<li>首先记录 <code>用户-&gt;物品</code> 的索引, 记录每个用户最近感兴趣的物品.<br />
</li>
<li>然后建立 <code>物品-&gt;物品</code> 的索引, 计算物品两两相似度, 并且取最相似的topk, 从而给定一个物品, 我们能够快速返回最相似的k个物品.</li>
</ul>
<p>线上:</p>
<ul>
<li>给定用户ID, 通过 <code>用户-&gt;物品</code> 索引, 找出用户近期感兴趣物品列表(last_n)<br />
</li>
<li>对于last_n, 我们通过 <code>物品-&gt;物品</code> 索引, 找出最相似的k个物品<br />
</li>
<li>对于取回的nk个物品, 用公式计算用户对物品的感兴趣程度<br />
</li>
<li>返回100个分数最高的物品作为召回结果</li>
</ul>
<p>总结:</p>
<p>使用索引离线计算量大, 线上计算量小. 不过离线本身计算不是太复杂都是可以接受的, 主要线上必须能够迅速给出结果, 这种方式线上可以快速得到反馈, 所以能够得到使用.</p>
<h2 id="swing">Swing</h2>
<p>类似itemCF, 不过区别的地方在于相似度计算, itemCF中物品重合用户越多表示越相似</p>
<p>Swing从另一个角度出发: 如果两个用户本身交集很小, 但是同时喜欢物品i和物品j, 那么说明i和j相似. 公式如下</p>
<p><span class="math display">\[
s(i, j) = \sum_{u \in U_i \cap U_j} \sum_{v \in U_i \cap U_j} \frac{1}{\alpha + \left| I_u \cap I_v \right|}
\]</span></p>
<p><code>$ U_i $</code>表示点击商品i的所有用户, <code>$ I_u $</code>表示用户u点击的所有商品, 翻译过来就是: 对于共同点击商品i,j的用户，如果用户之间共同点击的商品越少则商品 i,j 就越相似.</p>
<h2 id="usercf">userCF</h2>
<p><span class="math display">\[
\sum_j sim(user, user_j) \times like(user_j, item)
\]</span></p>
<p>几乎和itemCF完全一致,区别在于相似度为user与user之间. 另外就是userCF中存在一个降低热门物品权重的子问题, 当某用户的相似用户集里面很多人喜欢某个热门物品的时候, 我们应该降低热门物品的权重, 比如下图就采用了 1/log(1+热门程度)这种方式来解决此问题</p>
<p><img src="userCF.png" /></p>
<p>工业化使用流程也和itemCF很类似, 建立 <code>用户-&gt;物品</code> 索引和 <code>用户-&gt;用户</code> 索引, 然后快速返回最相似的k个用户和用户最喜欢的last_n个物品, 复杂度kn.</p>
<h2 id="矩阵补充not-working">矩阵补充(not working)</h2>
<p>思路非常简单: <strong>每个user对应一个embedding, 每个item对应一个embedding, 利用内积来预测用户评分从而学习embedding</strong>.</p>
<p>缺点:</p>
<ol type="1">
<li>只利用了embedding, 其他所有信息都没有使用(比如物品的物品属性, 关键词, 地理位置等, 用户的性别,年龄,感兴趣类别等).<br />
</li>
<li>其次, 负样本选择也有问题: 样本曝光之后被点击算正样本是正确的, 但是不点击并不代表是用户不感兴趣, 只能算作score没有真正的正样本高,这种样本其实本身应该被算作正样本, 最起码在召回阶段应该是正样本, 在后面的精排阶段算作负样本是可以的.<br />
</li>
<li>训练方法只用了内积, 不如余弦相似度.<br />
</li>
<li>最后是作者提到的矩阵补充使用regression, 就task type而言不如classification并表示工业界一般都是classification.</li>
</ol>
<h3 id="工业界做法复杂度处理">工业界做法(复杂度处理)</h3>
<p><strong>存储</strong>: 用户可以直接存kv表, 通过查询用户k从而得到用户的embedding值v. 而item的话因为数量庞大, 所以索引构造比较复杂, 从后面的内容来看, 似乎是通过将item分扇区来建立索引了.</p>
<p><strong>查找</strong>: 用户可以直接查表, 而求内积理论就需要枚举item然后获取向量然后求解. 但是这里存在问题, 如果靠枚举的话, 时间复杂度正比物品数量, 而物品的数量又特别庞大, 这是不可接受的.</p>
<p><strong>Approximate Nearest Neighbor Search</strong>: Milvus, Faiss, Hnswlib等系统就支持最近邻查找.</p>
<p>衡量标准也有如下:</p>
<ul>
<li>L2距离<br />
</li>
<li>内积<br />
</li>
<li>夹角余弦(cosine similarity)</li>
</ul>
<p>假如系统不支持余弦相似度, 可以对模做归一化, 从而内积即余弦相似度.</p>
<p>最近邻查找就是将点在空间中划分<strong>扇区</strong>, 取<strong>扇区代表向量</strong>与目标用户求相似度, 从而知道用户与哪一个扇区相似度较高. 进而我们通过扇区找到扇区内所有点, 再枚举所有点做内积. 这样复杂度可以从 <code>n</code> 变成 <code>$ \sqrt(n) $</code>.</p>
<h2 id="双塔模型">双塔模型</h2>
<h3 id="结构">结构</h3>
<p>类似矩阵召回, 但是是升级版. 矩阵召回直接将embedding做相似度计算, 而双塔模型则是将特征完全融合之后再求相似度.</p>
<p><img src="two_tower.png" /></p>
<ul>
<li>id信息会扩充为embedding; 离散特征类别少用one-hot, 类别多用多种embedding; 连续变量做归一化和一些简单预处理.<br />
</li>
<li>concat之后feed到神经网络, 求出用户或者物品的表征.<br />
</li>
<li>最后基于两个表征求余弦相似度.</li>
</ul>
<h3 id="训练">训练</h3>
<p>训练模式存在三种, pointwise, pairwise, listwise.</p>
<ol type="1">
<li>pointwise: 独立看待每个样本, 然后做二分类. 鼓励正样本预测1, 负样本预测-1. 然后样本一般正:负=1:2或者1:3(作者原话:"我也不知道为什么但互联网大厂的人都这么做").<br />
</li>
<li>pairwise: 正负样本每一组每一组地看. 基本思路是鼓励预测的正样本相似度大于负样本相似度; 如果cos(a, b+) - cos(a, b-) &gt; threshold, 则我们认为没有损失. 损失函数可以用triplet hinge loss: <code>$ L(a, b+, b-) = max\&#123;0, cos(a, b-) + threshold - cos(a, b+)\&#125; $</code>, 或者换成logistic也可以, 反正能正确反应正负样本关系即可.<br />
</li>
<li>listwise: 取一个正样本和多个负样本, 然后用softmax和crossentropy, 目标是softmax之后的正样本趋近于1, 而负样本趋近于0.</li>
</ol>
<h3 id="正负样本">正负样本</h3>
<p><strong>正样本</strong>: 曝光且有点击的用户物品二元组.</p>
<p>问题: 少量物品会占大多数点击,导致正样本大多数是热门物品.</p>
<p>解决方案: 过采样冷门物品和降采样热门物品.</p>
<ul>
<li>过采样(up-sampling): 一个样本出现多次.<br />
</li>
<li>降采样(down-sampling): 一些样本被抛弃.</li>
</ul>
<p><strong>负样本</strong>: 主要有三个阶段</p>
<ul>
<li>召回没被选到的 -&gt; 简单负样本<br />
</li>
<li>粗排和精排没有选到的 -&gt; 困难负样本<br />
</li>
<li>参加重排但是用户没有点击的 -&gt; 召回阶段应该被算作正样本, 排序阶段算负样本</li>
</ul>
<p><strong>简单负样本</strong>:<br />
未被召回的物品大概率是用户不感兴趣的, 而未被召回的物品约等于全体物品, 所以可以直接从全体物品抽样做负样本.</p>
<p>但是如果<strong>均匀抽样</strong>, 因为大部分物品都是冷门物品, 那么相当于冷门物品更容易被当作负样本, 而正样本大多数是热门物品, 这样对冷门物品不公平.</p>
<p>所以一般采用<strong>非均匀抽样</strong>, 目的是<strong>打压热门物品</strong>, 负样本抽样概率和热门程度相关, 比如可以用采样概率正比于点击率的0.75次方来表示.</p>
<p>但这种方式在batch内采样可能会出现问题: 一个batch提供的是用户和物品的二元组, 用户点击了其中一个物品而没有点击其他物品, 从而保证有n*(n-1)个简单负样本. 然而一个batch中一个物品的出现概率是正比于其点击次数的, 物品成为负样本的概率本应该正比于点击率的0.75次方, 但是这里却变成了点击率的一次方: 这导致了对热门物品惩罚过狠, 会造成偏差.</p>
<p>小红书采用了<a target="_blank" rel="noopener" href="https://dl.acm.org/doi/10.1145/3298689.3346996">Sampling-bias-corrected neural modeling for large corpus item recommendations</a>里的策略来做出调整, 具体做法如下:</p>
<ul>
<li>物品被抽样到的概率 <code>$ p_i \propto 点击次数 $</code>.<br />
</li>
<li>一般用于预估用户兴趣采用的是 <code>$ cos(a, b_i) $</code>.<br />
</li>
<li>做训练的时候应该调整为 <code>$ cos(a, b_i) - logp_i $</code> 从而避免对热门物品的过分打压, 而等线上做召回的时候还是用 <code>$ cos(a, b_i) $</code>.</li>
</ul>
<p><strong>困难负样本</strong>:</p>
<p>召回阶段淘汰的物品(全体物品, 即简单负样本): 容易区分<br />
被粗排淘汰的物品(困难负样本): 比较难区分<br />
精排靠后的物品(困难负样本): 非常难区分</p>
<p><strong>工业界做法</strong>:</p>
<p>混合几种负样本, 50%简单负样本, 50%是困难负样本</p>
<p><strong>为什么曝光为点击不可以用作负样本</strong></p>
<p><img src="neg_sample.png" /></p>
<h3 id="线上召回">线上召回</h3>
<p>双塔模型首先是特征提取部分, 这里分为用户特征和物品特征两部分.</p>
<p>其中物品特征由于计算量大, 所以我们必须选择离线计算存储的方式: 首先模型进行训练, 训练完毕之后我们把物品的特征向量存进向量数据库, 然后向量数据库建索引以方便查找. 之后线上有需求的时候直接通过索引取出物品特征.</p>
<p>而用户特征我们可以选择离线存储然后索引获取; 也可以选择线上直接算一个. 因为用户向量只有一个, 所以计算量不大, 线上实时计算是可以接受的. 这样做的好处是用户的兴趣随时变化的话我们也能够检测得到, 推荐效果会更好.</p>
<h3 id="全量更新和增量更新">全量更新和增量更新</h3>
<p>全量更新: 指的是每天一次, 在昨天的模型基础之上对昨天的新数据进行重新学习(类似LLM的全调参)</p>
<p>增量更新: 用户的兴趣随时会发生改变, 那么就需要实时收集线上数据做流式处理, 生成tfrecord然后对模型做增量更新(指学习embedding而不做神经网络的学习). 最后发布用户的id embedding供用户塔线上计算.</p>
<p><strong>只做增量不做全量更新会导致偏差</strong>: 短时间的流式信息是没有被shuffle的, 训练效果不如全量更新时shuffle来的效果好, 其次我个人理解是全量更新除此之外还会保持神经网络对embedding层的适应, 从而使模型效果更好.</p>
<h3 id="自监督学习">自监督学习</h3>
<p>解决问题: 推荐系统的头部效应-&gt;即少部分物品占大部分点击, 大部分物品展少量点击-&gt;高点击物品表征学得好,低点击物品表征学得差.</p>
<p>带自监督学习的双塔模型基本模型还是双塔模型, 不过loss由两部分构成: 一部分是mainLoss, 另一部分是selfloss(自监督loss).</p>
<p>第一部分的loss是crossentropy, 如下图. 其中数据取自batch, 每个用户对应一个item, 即1对n的listwise learning.</p>
<p><img src="two_tower_mainloss.png" /></p>
<p>上面这个损失函数还有点小问题, 即我们前面提到过的纠偏, 训练的时候 <code>$ cos(a_i, b_j) $</code> 得换成 <code>$ cos(a_i, b_j) - logp_j $</code>.</p>
<p><img src="twotower_mainloss_withbias.png" /></p>
<p>第二部分是自监督学习, 具体结构如下图</p>
<p><img src="twotower_self.png" /></p>
<p>具体想法就是对物品做特征变换,物品i可以生成特征bi'和bi'',物品j可以生成特征bj'和bj''.</p>
<p>然后我们的目标是</p>
<ol type="1">
<li>让物品i和物品j的特征差异尽量大.<br />
</li>
<li>而单个物品i经过不同特征变换的输出特征应该尽量相似.</li>
</ol>
<p><strong>特征变换种类</strong>:</p>
<ol type="1">
<li>random mask: 随机挑选一些离散特征, 直接对其mask, 比如类目本来是{数码,摄影}, mask之后变成{default}.<br />
</li>
<li>dropout: 如果物品是多值离散特征, 我们随机丢弃其中50%的值, 比如{数码,摄影}, dropout之后变成{数码}.<br />
</li>
<li>互补特征: 相当于把特征split为两份, 两份互不重叠.<br />
</li>
<li>mask关联特征: mask掉一系列关联性强的特征.</li>
</ol>
<p>对于关联特征这个仔细说一下: 我们取p(u)为u特征出现的概率, p(v)为v特征出现的概率, 那么我们可以用互信息(mutual information)来表示特征之间的关联.</p>
<p><span class="math display">\[
MI(U,V) = \sum_{u \in U} \sum_{v \in V} p(u,v) \cdot log\frac{p(u,v)}{p(u)p(v)}
\]</span></p>
<p><strong>做法</strong>: 假设有k个特征, 那么就可以构成k * k的特征矩阵, 然后我们随机选一个种子, 找到与种子最相关的k/2种特征, mask掉最相关的k/2, 然后保留剩下k/2.</p>
<p><strong>好处</strong>: 比其他的特征变换效果更好</p>
<p><strong>坏处</strong>: 方法复杂, 实现难度大, 不容易维护.</p>
<p>最终损失函数</p>
<p><img src="two_tower_loss.png" /></p>
<h2 id="deep-retrieval字节">Deep Retrieval(字节)</h2>
<p>类似阿里的TDM. 双塔模型把物品表示为向量, 而deep retrieval把物品表示为路径, 然后线上查找用户最匹配的路径.</p>
<p>整体步骤如下:</p>
<ol type="1">
<li>给定用户特征x, 用神经网络预测用户对路径path = [a, b, c]的兴趣, 分数记为 p(path | x).<br />
</li>
<li>用beam search来寻找分数p(path | x)最高的s条path.<br />
</li>
<li>利用索引 path -&gt; List_item来召回路径上的n个物品.<br />
</li>
<li>对返回的最多s*n个物品做初步排序, 然后返回分数最高的若干物品.</li>
</ol>
<h3 id="用户对路径的兴趣">用户对路径的兴趣</h3>
<p>假设路径为path = [a, b, c], 用户特征为x. 那么:</p>
<ul>
<li>给定x, 用户对节点a的兴趣为p1(a | x)<br />
</li>
<li>给定x,a, 用户对节点b的兴趣为p2(b | a;x)<br />
</li>
<li>给定x,a,b, 用户对节点c的兴趣为p3(c | a,b;x)</li>
</ul>
<p>最终用户对path = [a, b, c]的兴趣为:<br />
p(a, b, c|x) = p1(a | x) * p2(b | a;x) * p3(c | a,b;x)</p>
<p><img src="x2abc.png" /></p>
<p>注意图中神经网络是不同的神经网络, 不共享参数.</p>
<h3 id="用户对路径的学习方式">用户对路径的学习方式</h3>
<p>首先这里为了让模型学到用户和路径的关系, 我们样本层面只用到了正样本, 即 click(user, item) = 1. 然后使用下面的思路训练神经网络</p>
<ul>
<li>假设物品可以表征为J条路径:[a1, a2, a3], ... [aj, bj, cj].<br />
</li>
<li>用户的兴趣为 p(a, b, c|x) = p1(a | x) * p2(b | a;x) * p3(c | a,b;x)<br />
</li>
<li>如果用户点击了物品说明用户对物品感兴趣<br />
</li>
<li>那么就存在 <code>$ \sum_&#123;j=1&#125;^&#123;J&#125; p(a_j, b_j, c_j | x) $</code> 尽可能大.<br />
</li>
<li>所以损失函数可以用 <code>$ loss = -log(\sum_&#123;j=1&#125;^&#123;J&#125; p(a_j, b_j, c_j | x)) $</code>.</li>
</ul>
<h3 id="学习物品表征">学习物品表征</h3>
<p>前面说到用户的兴趣为<code>$ p(a, b, c|x) = p_1(a | x) \times p_2(b | a;x) \times p_3(c | a,b;x) $</code>, 我们把这个表示为 <code>$ p(path | user) $</code>.</p>
<p>那么item和path的相关性就可以表示为:</p>
<p><span class="math display">\[
score(item, path) = \sum_{user}p(path|user) \times click(user, item)
\]</span></p>
<p>前面为用户对路径的兴趣, 后面为用户是否点击了物品. 然后我们依据score来选出J条路径作为item的表征.</p>
<p>即我们通过将user作为中介, 尝试获得item的路径表征.</p>
<p><strong>loss</strong>:<br />
即然选出了J条路径 <code>$ \Pi = \&#123;path_1 ... path_j\&#125; $</code>来作为物品表征.</p>
<p>那么损失函数就可以写成</p>
<p><span class="math display">\[
loss(item, \Pi) = - log(\sum_{j=1}^J score(item, path_j))
\]</span></p>
<p>即路径与物品越相关, score就越大, loss就越小.</p>
<p><strong>regularization</strong>:</p>
<p>为了避免过多物品集中在一条path的情况, 我们加上正则项. <span class="math display">\[
reg(path_j) = (number\,of\,items\,on\,path_j)^4.
\]</span></p>
<h2 id="其他召回通道">其他召回通道</h2>
<p><strong>地理位置召回</strong>: GeoHash召回, 同城召回.</p>
<p><strong>作者召回</strong>: 关注的作者, 有交互的作者, 相似的作者.</p>
<p><strong>缓存召回</strong>: 设置缓存,复用前面做精排的结果. 缓存机制: 一旦成功曝光就移出缓存;超出缓存大小移除最先进入的;最多召回10次,达到后退场;最多保存3天,满3天退场.</p>
<h2 id="不适合召回的模型"><strong>不适合召回的模型</strong></h2>
<p>召回的目标是大量数据, 所以需求遍历的模型就不适合召回.</p>
<p><img src="non_recall.png" /></p>
<p>个人理解:</p>
<p>这个模型的神经网络需要用户和物品两边的特征输入并做前期的特征融合, 这种方法就必须<strong>线上</strong>使用神经网络跑一遍遍历, 复杂度不可接受.</p>
<p>对比之下双塔模型后期融合, 前期表征计算完毕可以直接存储, 需求计算相似度的时候直接依据索引取出, 复杂度仅在于相似度计算而不用线上再跑神经网络, 这才是召回应该采用的模型.</p>
<h2 id="曝光过滤">曝光过滤</h2>
<p>一般在召回阶段做, 如果用户看过某个物品, 那么大概率用户不会想再看一遍, 所以我们要在召回阶段把重复物品筛选下去.</p>
<p>如果某用户看过n个物品, 本次召回k个物品, 那么暴力对比会有nk复杂度. 复杂度较大, 因此需要优化.</p>
<h3 id="bloom-filter">bloom filter</h3>
<p>即做曝光过滤的方法之一.</p>
<p>方法: 其通过对物品hash然后写表的方式来做记录, 然后通过读取hash表的方式来判断是否以前存过这个物品.</p>
<p>因此如果bloom filter表示没记录过这个物品, 那么这个物品一定没被推过; 如果bloom filter表示这个物品以前记录过, 那么这个物品以前可能记录过也可能没记录过(存在误伤).</p>
<p><img src="bloomfilter.png" /></p>
<p>我们假设曝光物品集合大小为n, 二进制向量维度为m, 用了k个哈希函数. 那么bloom filter误伤的概率为</p>
<p><span class="math display">\[
\delta \approx (1 - exp(-\frac{kn}{m}))^k
\]</span></p>
<p>n越大, 向量的1越多, 越容易误伤; m越大, 向量空间越大, 越不容易碰撞; k太大太小都不好, 需要取最优.</p>
<p>作者给出最优参数(不太清楚怎么求的, 工业化场景吧).</p>
<p><span class="math display">\[
k = 1.44 \cdot ln(\frac{1}{\delta}),  m = 2n \cdot ln(\frac{1}{\delta})
\]</span></p>
<p><strong>实际业务图</strong></p>
<p><img src="bloomfilter_data.png" /></p>
<p>用户获取数据之后我们需要尽快写表来方便下次召回, 需要用实时流处理: 把曝光物品写kafka消息队列然后flink读取消息队列并计算物品hash并写到bloomfilter的表上.</p>
<p><strong>缺点</strong>:</p>
<p>只能添加物品不能删除物品, 即一旦向量被写入了1就不可从1写回0, 否则会影响其他物品.</p>
<p>如果我们想移除一个月前的曝光物品, 让bloomfilter不记录它们了来降低误伤率, 这只能通过重新计算二进制向量来实现.</p>

  </div>
</article>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
        
          <li><a href="/">Home</a></li>
        
          <li><a href="/about/">About</a></li>
        
          <li><a href="/archives/">Writing</a></li>
        
          <li><a href="/categories/">Category</a></li>
        
          <li><a href="/search/">Search</a></li>
        
      </ul>
    </div>

    
    
      <div id="toc-footer" style="display: none">
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#tutorial-reference"><span class="toc-number">2.</span> <span class="toc-text">Tutorial &amp; Reference</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#background"><span class="toc-number">3.</span> <span class="toc-text">Background</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#data%E7%9B%B8%E5%85%B3"><span class="toc-number">3.1.</span> <span class="toc-text">Data相关</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8C%87%E6%A0%87%E7%9F%AD%E6%9C%9F%E6%8C%87%E6%A0%87"><span class="toc-number">3.2.</span> <span class="toc-text">指标(短期指标)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8C%97%E6%9E%81%E6%98%9F%E6%8C%87%E6%A0%87%E9%95%BF%E6%9C%9F%E6%8C%87%E6%A0%87"><span class="toc-number">3.3.</span> <span class="toc-text">北极星指标(长期指标)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E6%B5%81%E7%A8%8B"><span class="toc-number">3.4.</span> <span class="toc-text">实验流程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#ab%E6%B5%8B%E8%AF%95"><span class="toc-number">3.4.1.</span> <span class="toc-text">AB测试</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E5%88%86%E6%A1%B6"><span class="toc-number">3.4.1.1.</span> <span class="toc-text">随机分桶</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E5%B1%82%E5%AE%9E%E9%AA%8C"><span class="toc-number">3.4.1.2.</span> <span class="toc-text">分层实验</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#holdout%E6%9C%BA%E5%88%B6"><span class="toc-number">3.4.1.3.</span> <span class="toc-text">Holdout机制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%8D%E8%BD%AC%E5%AE%9E%E9%AA%8C"><span class="toc-number">3.4.1.4.</span> <span class="toc-text">反转实验</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#pipline"><span class="toc-number">4.</span> <span class="toc-text">Pipline</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%AC%E5%9B%9E"><span class="toc-number">5.</span> <span class="toc-text">召回</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#itemcf"><span class="toc-number">5.1.</span> <span class="toc-text">itemCF</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#similarity"><span class="toc-number">5.1.1.</span> <span class="toc-text">similarity</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cosine-similarity"><span class="toc-number">5.1.2.</span> <span class="toc-text">cosine similarity</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B7%A5%E4%B8%9A%E5%8C%96%E4%BD%BF%E7%94%A8"><span class="toc-number">5.1.3.</span> <span class="toc-text">工业化使用</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#swing"><span class="toc-number">5.2.</span> <span class="toc-text">Swing</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#usercf"><span class="toc-number">5.3.</span> <span class="toc-text">userCF</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9F%A9%E9%98%B5%E8%A1%A5%E5%85%85not-working"><span class="toc-number">5.4.</span> <span class="toc-text">矩阵补充(not working)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B7%A5%E4%B8%9A%E7%95%8C%E5%81%9A%E6%B3%95%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%A4%84%E7%90%86"><span class="toc-number">5.4.1.</span> <span class="toc-text">工业界做法(复杂度处理)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%8C%E5%A1%94%E6%A8%A1%E5%9E%8B"><span class="toc-number">5.5.</span> <span class="toc-text">双塔模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E6%9E%84"><span class="toc-number">5.5.1.</span> <span class="toc-text">结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83"><span class="toc-number">5.5.2.</span> <span class="toc-text">训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AD%A3%E8%B4%9F%E6%A0%B7%E6%9C%AC"><span class="toc-number">5.5.3.</span> <span class="toc-text">正负样本</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BA%BF%E4%B8%8A%E5%8F%AC%E5%9B%9E"><span class="toc-number">5.5.4.</span> <span class="toc-text">线上召回</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%A8%E9%87%8F%E6%9B%B4%E6%96%B0%E5%92%8C%E5%A2%9E%E9%87%8F%E6%9B%B4%E6%96%B0"><span class="toc-number">5.5.5.</span> <span class="toc-text">全量更新和增量更新</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="toc-number">5.5.6.</span> <span class="toc-text">自监督学习</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#deep-retrieval%E5%AD%97%E8%8A%82"><span class="toc-number">5.6.</span> <span class="toc-text">Deep Retrieval(字节)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%A8%E6%88%B7%E5%AF%B9%E8%B7%AF%E5%BE%84%E7%9A%84%E5%85%B4%E8%B6%A3"><span class="toc-number">5.6.1.</span> <span class="toc-text">用户对路径的兴趣</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%A8%E6%88%B7%E5%AF%B9%E8%B7%AF%E5%BE%84%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%96%B9%E5%BC%8F"><span class="toc-number">5.6.2.</span> <span class="toc-text">用户对路径的学习方式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0%E7%89%A9%E5%93%81%E8%A1%A8%E5%BE%81"><span class="toc-number">5.6.3.</span> <span class="toc-text">学习物品表征</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B6%E4%BB%96%E5%8F%AC%E5%9B%9E%E9%80%9A%E9%81%93"><span class="toc-number">5.7.</span> <span class="toc-text">其他召回通道</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%8D%E9%80%82%E5%90%88%E5%8F%AC%E5%9B%9E%E7%9A%84%E6%A8%A1%E5%9E%8B"><span class="toc-number">5.8.</span> <span class="toc-text">不适合召回的模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9B%9D%E5%85%89%E8%BF%87%E6%BB%A4"><span class="toc-number">5.9.</span> <span class="toc-text">曝光过滤</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#bloom-filter"><span class="toc-number">5.9.1.</span> <span class="toc-text">bloom filter</span></a></li></ol></li></ol></li></ol>
      </div>
    

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/&text=工业化推荐系统相关"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/&title=工业化推荐系统相关"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/&is_video=false&description=工业化推荐系统相关"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=工业化推荐系统相关&body=Check out this article: http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/"><i class="fa-solid fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/&title=工业化推荐系统相关"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/&title=工业化推荐系统相关"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/&title=工业化推荐系统相关"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/&title=工业化推荐系统相关"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/&name=工业化推荐系统相关&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://example.com/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/&t=工业化推荐系统相关"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fa-solid fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        
          <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fa-solid fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fa-solid fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2016-2024
    blacsheep
  </div>
  <div class="footer-right">
    <nav>
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     --><!--
       --><li><a href="/categories/">Category</a></li><!--
     --><!--
       --><li><a href="/search/">Search</a></li><!--
     -->
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->



  <link rel="preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" crossorigin="anonymous" onload="this.onload=null;this.rel='stylesheet'"/>


    <!-- jquery -->

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" crossorigin="anonymous"></script>




<!-- clipboard -->

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.7/clipboard.min.js" crossorigin="anonymous"></script>
  
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="fa-regular fa-clone"></i>';
    btn += '</span>';
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Baidu Analytics -->

<!-- Cloudflare Analytics -->

<!-- Disqus Comments -->

<!-- utterances Comments -->

</body>
</html>
