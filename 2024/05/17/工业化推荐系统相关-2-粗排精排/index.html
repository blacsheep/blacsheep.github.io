<!DOCTYPE html>
<html lang=en>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5" />
    <meta name="description" content="粗排和精排 很相似, 但是精排模型更大, 特征更多. 输入用户特征, 物品特征以及统计特征, 模型预测并输出相关指标, 最终我们对输出指标打分, 这个分数就作为最终排序分数. 回忆一下指标:  点击率(CTR): 点击次数 &#x2F; 曝光次数  点赞率: 点赞次数 &#x2F; 点击次数  收藏率: 收藏次数 &#x2F; 点击次数  转发率: 转发次数 &#x2F; 点击次数   我们首先对各种指标进行预测, 然后融合这些预估分数">
<meta property="og:type" content="article">
<meta property="og:title" content="工业化推荐系统相关(2)-粗排精排">
<meta property="og:url" content="http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/index.html">
<meta property="og:site_name" content="blacsheep&#39;s blog">
<meta property="og:description" content="粗排和精排 很相似, 但是精排模型更大, 特征更多. 输入用户特征, 物品特征以及统计特征, 模型预测并输出相关指标, 最终我们对输出指标打分, 这个分数就作为最终排序分数. 回忆一下指标:  点击率(CTR): 点击次数 &#x2F; 曝光次数  点赞率: 点赞次数 &#x2F; 点击次数  收藏率: 收藏次数 &#x2F; 点击次数  转发率: 转发次数 &#x2F; 点击次数   我们首先对各种指标进行预测, 然后融合这些预估分数">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92.png">
<meta property="og:image" content="http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/pipline.png">
<meta property="og:image" content="http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/%E5%A4%9A%E7%9B%AE%E6%A0%87%E6%A8%A1%E5%9E%8B.png">
<meta property="og:image" content="http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/MMoE_first.png">
<meta property="og:image" content="http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/MMoE_second.png">
<meta property="og:image" content="http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/three_tower.png">
<meta property="og:image" content="http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/FM_optimized.png">
<meta property="og:image" content="http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/Cross_Network.png">
<meta property="og:image" content="http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/DCN.png">
<meta property="og:image" content="http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/voice_LHUC.png">
<meta property="og:image" content="http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/Rank_LHUC.png">
<meta property="og:image" content="http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/SENet.png">
<meta property="og:image" content="http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/BilinearCross.png">
<meta property="og:image" content="http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/FiBiNet.png">
<meta property="og:image" content="http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/LastN.png">
<meta property="og:image" content="http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/DIN.png">
<meta property="og:image" content="http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/SIM.png">
<meta property="og:image" content="http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/%E8%A7%86%E9%A2%91%E5%BB%BA%E6%A8%A1.png">
<meta property="article:published_time" content="2024-05-17T06:41:35.000Z">
<meta property="article:modified_time" content="2024-06-24T08:40:51.799Z">
<meta property="article:author" content="blacsheep">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92.png">
    
    
      
        
          <link rel="shortcut icon" href="/images/favicon.ico">
        
      
      
        
          <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
        
      
      
        
          <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
        
      
    
    <!-- title -->
    <title>工业化推荐系统相关(2)-粗排精排</title>
    <!-- async scripts -->
    <!-- Google Analytics -->


    <!-- Umami Analytics -->


    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
    <!-- rss -->
    
    
	<!-- mathjax -->
	
		<script type="text/x-mathjax-config">
		  MathJax.Hub.Config({
			tex2jax: {
			  skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
			  inlineMath: [['$','$']]
			}
		  });
		</script>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>
	
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#" aria-label="Menu"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#" aria-label="Menu"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" aria-label="Top" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fa-solid fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     --><!--
       --><li><a href="/categories/">Category</a></li><!--
     --><!--
       --><li><a href="/search/">Search</a></li><!--
     -->
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" aria-label="Previous post" href="/2024/05/24/%E6%9D%82%E8%B0%88/"><i class="fa-solid fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" aria-label="Next post" href="/2024/05/13/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3/"><i class="fa-solid fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" aria-label="Back to top" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" aria-label="Share post" href="#"><i class="fa-solid fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/&text=工业化推荐系统相关(2)-粗排精排"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/&title=工业化推荐系统相关(2)-粗排精排"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/&is_video=false&description=工业化推荐系统相关(2)-粗排精排"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=工业化推荐系统相关(2)-粗排精排&body=Check out this article: http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/"><i class="fa-solid fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/&title=工业化推荐系统相关(2)-粗排精排"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/&title=工业化推荐系统相关(2)-粗排精排"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/&title=工业化推荐系统相关(2)-粗排精排"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/&title=工业化推荐系统相关(2)-粗排精排"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/&name=工业化推荐系统相关(2)-粗排精排&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/&t=工业化推荐系统相关(2)-粗排精排"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    
    
      <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%B2%97%E6%8E%92%E5%92%8C%E7%B2%BE%E6%8E%92"><span class="toc-number">1.</span> <span class="toc-text">粗排和精排</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E6%95%B0%E6%8D%AE"><span class="toc-number">1.1.</span> <span class="toc-text">特征数据</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#profile"><span class="toc-number">1.1.1.</span> <span class="toc-text">Profile</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#user-profile"><span class="toc-number">1.1.1.1.</span> <span class="toc-text">User Profile</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#item-profile"><span class="toc-number">1.1.1.2.</span> <span class="toc-text">Item Profile</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%9F%E8%AE%A1%E7%89%B9%E5%BE%81"><span class="toc-number">1.1.2.</span> <span class="toc-text">统计特征</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%94%A8%E6%88%B7%E7%BB%9F%E8%AE%A1%E7%89%B9%E5%BE%81"><span class="toc-number">1.1.2.1.</span> <span class="toc-text">用户统计特征</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AC%94%E8%AE%B0%E7%89%A9%E5%93%81%E7%BB%9F%E8%AE%A1%E7%89%B9%E5%BE%81"><span class="toc-number">1.1.2.2.</span> <span class="toc-text">笔记(物品)统计特征</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF%E7%89%B9%E5%BE%81context"><span class="toc-number">1.1.3.</span> <span class="toc-text">场景特征(context)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E5%A4%84%E7%90%86"><span class="toc-number">1.1.4.</span> <span class="toc-text">特征处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B4%E4%BD%93%E6%B5%81%E7%A8%8B"><span class="toc-number">1.1.5.</span> <span class="toc-text">整体流程</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E7%9B%AE%E6%A0%87%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.2.</span> <span class="toc-text">多目标模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E7%BB%86%E8%8A%82"><span class="toc-number">1.2.1.</span> <span class="toc-text">模型细节</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">1.2.2.</span> <span class="toc-text">损失函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E7%9A%84%E5%9B%B0%E9%9A%BE-%E7%B1%BB%E5%88%AB%E4%B8%8D%E5%B9%B3%E8%A1%A1"><span class="toc-number">1.2.3.</span> <span class="toc-text">训练的困难-类别不平衡</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%99%8D%E9%87%87%E6%A0%B7%E6%A0%A1%E5%87%86"><span class="toc-number">1.2.4.</span> <span class="toc-text">降采样校准</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#mmoemulti-gate-mixture-of-experts"><span class="toc-number">1.3.</span> <span class="toc-text">MMoE(Multi-gate Mixture-of-Experts)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AD%98%E5%9C%A8%E9%97%AE%E9%A2%98"><span class="toc-number">1.3.1.</span> <span class="toc-text">存在问题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E5%A1%94%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.4.</span> <span class="toc-text">三塔模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#fmfactorization-machine"><span class="toc-number">1.5.</span> <span class="toc-text">FM(Factorization Machine)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#dcn"><span class="toc-number">1.6.</span> <span class="toc-text">DCN</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lhuc"><span class="toc-number">1.7.</span> <span class="toc-text">LHUC</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8A%A0%E6%9D%83%E5%92%8C%E4%BA%A4%E5%8F%89"><span class="toc-number">1.8.</span> <span class="toc-text">加权和交叉</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#senet"><span class="toc-number">1.8.1.</span> <span class="toc-text">SENet</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#bilinear-cross"><span class="toc-number">1.8.2.</span> <span class="toc-text">Bilinear Cross</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#fibinet"><span class="toc-number">1.8.3.</span> <span class="toc-text">FiBiNet</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%97%E5%BB%BA%E6%A8%A1lastn%E7%89%B9%E5%BE%81"><span class="toc-number">1.9.</span> <span class="toc-text">用户行为序列建模(LastN特征)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#din%E6%A8%A1%E5%9E%8B%E5%AF%B9lastn%E7%9A%84%E4%BC%98%E5%8C%96"><span class="toc-number">1.10.</span> <span class="toc-text">DIN模型(对LastN的优化)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#sim%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.11.</span> <span class="toc-text">SIM模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#search"><span class="toc-number">1.11.1.</span> <span class="toc-text">Search</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#attention%E9%83%A8%E5%88%86"><span class="toc-number">1.11.2.</span> <span class="toc-text">Attention部分</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A2%84%E4%BC%B0%E5%88%86%E6%95%B0%E8%9E%8D%E5%90%88"><span class="toc-number">1.12.</span> <span class="toc-text">预估分数融合</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%86%E9%A2%91%E6%92%AD%E6%94%BE%E5%BB%BA%E6%A8%A1"><span class="toc-number">1.13.</span> <span class="toc-text">视频播放建模</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%B6%E9%95%BF"><span class="toc-number">1.13.1.</span> <span class="toc-text">时长</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%8C%E6%92%AD"><span class="toc-number">1.13.2.</span> <span class="toc-text">完播</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%87%8D%E6%8E%92"><span class="toc-number">2.</span> <span class="toc-text">重排</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%89%A9%E5%93%81%E5%A4%9A%E6%A0%B7%E6%80%A7%E9%97%AE%E9%A2%98"><span class="toc-number">2.1.</span> <span class="toc-text">物品多样性问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%B8%E4%BC%BC%E5%BA%A6%E7%9A%84%E5%BA%A6%E9%87%8F"><span class="toc-number">2.1.1.</span> <span class="toc-text">相似度的度量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8F%90%E5%8D%87%E5%A4%9A%E6%A0%B7%E6%80%A7%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-number">2.1.2.</span> <span class="toc-text">提升多样性的方法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#maximal-marginal-relevancemmr"><span class="toc-number">2.2.</span> <span class="toc-text">Maximal Marginal Relevance(MMR)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#dpp"><span class="toc-number">2.3.</span> <span class="toc-text">DPP</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B6%85%E5%B9%B3%E8%A1%8C%E4%BD%93"><span class="toc-number">2.3.1.</span> <span class="toc-text">超平行体</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F"><span class="toc-number">2.3.2.</span> <span class="toc-text">推荐系统</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%87%8D%E6%8E%92%E7%9A%84%E8%A7%84%E5%88%99"><span class="toc-number">2.4.</span> <span class="toc-text">重排的规则</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%80%E5%A4%9A%E8%BF%9E%E7%BB%AD%E5%87%BA%E7%8E%B0k%E7%AF%87%E6%9F%90%E7%A7%8D%E7%AC%94%E8%AE%B0"><span class="toc-number">2.4.1.</span> <span class="toc-text">最多连续出现k篇某种笔记</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AF%8Fk%E7%AF%87%E7%AC%94%E8%AE%B0%E6%9C%80%E5%A4%9A%E5%87%BA%E7%8E%B0%E4%B8%80%E7%AF%87%E6%9F%90%E7%A7%8D%E7%AC%94%E8%AE%B0"><span class="toc-number">2.4.2.</span> <span class="toc-text">每k篇笔记最多出现一篇某种笔记</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%89%8Dt%E7%AF%87%E7%AC%94%E8%AE%B0%E6%9C%80%E5%A4%9A%E5%87%BA%E7%8E%B0k%E7%AF%87%E6%9F%90%E7%A7%8D%E7%AC%94%E8%AE%B0"><span class="toc-number">2.4.3.</span> <span class="toc-text">前t篇笔记最多出现k篇某种笔记</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#mr%E5%8A%A0%E8%A7%84%E5%88%99"><span class="toc-number">2.4.4.</span> <span class="toc-text">MR加规则</span></a></li></ol></li></ol></li></ol>
      </div>
    
  </span>
</div>

    
    <div class="content index py4 ">
        
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle p-name" itemprop="name headline">
        工业化推荐系统相关(2)-粗排精排
    </h1>



    <div class="meta">
      <span class="author p-author h-card" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span class="p-name" itemprop="name">blacsheep</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2024-05-17T06:41:35.000Z" class="dt-published" itemprop="datePublished">2024-05-17</time>
        
      
    </div>


      
    <div class="article-category">
        <i class="fa-solid fa-archive"></i>
        <a class="category-link" href="/categories/ML-Recommender-System/">ML Recommender System</a>
    </div>


      

    </div>
  </header>
  

  <div class="content e-content" itemprop="articleBody">
    <h1 id="粗排和精排">粗排和精排</h1>
<p>很相似, 但是精排模型更大, 特征更多.</p>
<p>输入用户特征, 物品特征以及统计特征, 模型预测并输出相关指标, 最终我们对输出指标打分, 这个分数就作为最终排序分数.</p>
<p>回忆一下指标:</p>
<ul>
<li>点击率(CTR): 点击次数 / 曝光次数<br />
</li>
<li>点赞率: 点赞次数 / 点击次数<br />
</li>
<li>收藏率: 收藏次数 / 点击次数<br />
</li>
<li>转发率: 转发次数 / 点击次数</li>
</ul>
<p><img src="粗排精排.png" /></p>
<p>我们首先对各种指标进行预测, 然后融合这些预估分数(比如加权), 然后对结果做截断和排序.</p>
<h2 id="特征数据">特征数据</h2>
<h3 id="profile">Profile</h3>
<p>主要描述静态的用户和物品的特征</p>
<h4 id="user-profile">User Profile</h4>
<ul>
<li>用户id(在对应阶段做embedding)<br />
</li>
<li>人口统计学数据: 性别, 年龄<br />
</li>
<li>账号信息: 新老账号, 活跃度<br />
</li>
<li>用户感兴趣的类别, 关键词, 品牌等</li>
</ul>
<h4 id="item-profile">Item Profile</h4>
<ul>
<li>物品ID(对应阶段做embedding)<br />
</li>
<li>发布时间<br />
</li>
<li>GeoHash, 所在城市<br />
</li>
<li>标题, 类目, 关键词, 品牌<br />
</li>
<li>字数, 图片数, 视频清晰度, 标签数<br />
</li>
<li>内容信息量, 图片美学</li>
</ul>
<h3 id="统计特征">统计特征</h3>
<p>描述一定时间内的用户和物品的统计数据</p>
<h4 id="用户统计特征">用户统计特征</h4>
<ul>
<li>30天/7天/1天/1小时的曝光数,点击数,点赞数等<br />
</li>
<li>对图文笔记点击率, 对视频的点击率<br />
</li>
<li>对不同笔记类型的点击率</li>
</ul>
<h4 id="笔记物品统计特征">笔记(物品)统计特征</h4>
<ul>
<li>笔记30天/7天/1天/1小时的曝光数,点击数,点赞数等<br />
</li>
<li>男用户的点击率, 女用户的点击率等<br />
</li>
<li>作者的粉丝数量, 发布的笔记数量, 以及笔记的消费指标等</li>
</ul>
<h3 id="场景特征context">场景特征(context)</h3>
<p>场景特征是依据用户请求的当前场景获取的.</p>
<ul>
<li>用户当前GeoHash, 城市等<br />
</li>
<li>发送请求的当前时间等<br />
</li>
<li>当前是否是周末, 是否是节日等<br />
</li>
<li>设备信息(比如安卓用户和苹果用户可能倾向不一样)</li>
</ul>
<h3 id="特征处理">特征处理</h3>
<p>离散变量embedding, 连续变量做分桶变成离散, 或者取log(1+x)之类的平滑操作以防止数值过大.</p>
<h3 id="整体流程">整体流程</h3>
<p><img src="pipline.png" /></p>
<p>首先用户发送请求, 主服务器接受请求然后转发给召回服务器, 召回服务器多路召回并把结果(召回物品id)返回给主服务器.</p>
<p>然后主服务器将物品id信息,用户id信息和context发给排序服务器, 排序服务器从对应数据库中取出数据. 其中用户数据库压力小(因为用户为1), 物品数据库压力大(压力乘以召回数大小). 也因此用户特征可以略微复杂一些,但物品特征需要尽量简单,否则到时候物品服务器压力会很大. 最后统计信息是包含实时结果的, 所以需要尽快将最新信息上传并提取. 特征打包过后丢tf服务器做计算, 最后返回结果.</p>
<h2 id="多目标模型">多目标模型</h2>
<h3 id="模型细节">模型细节</h3>
<p>更加详细一点的模型细节:</p>
<p><img src="多目标模型.png" /></p>
<h3 id="损失函数">损失函数</h3>
<p>训练的时候用的交叉熵做损失函数. 比如点击率预测为p1, 目标为y1.</p>
<p><span class="math display">\[
CrossEntropy(y_1, p_1) = - (y_1 \cdot lnp_1 + (1 - y_1) \cdot ln(1 - p_1))
\]</span></p>
<p>然后我们做加权</p>
<p><span class="math display">\[
Loss = \sum_{i=1}^4 \alpha_i \cdot CrossEntropy(y_i, p_i)
\]</span></p>
<h3 id="训练的困难-类别不平衡">训练的困难-类别不平衡</h3>
<p>困难: 每100次曝光, 我们可能有10次点击, 90次未点击; 每100次点击, 我们可能有10次收藏, 90次未收藏.</p>
<p>解决方案: 我们可以做down-sampling, 保留一部分负样本并舍弃其他负样本, 从而让正负样本更平衡, 同时还能节省计算.</p>
<h3 id="降采样校准">降采样校准</h3>
<p>但是这样又会有问题, 我们对负样本做downsampling会导致模型对点击率有高估. 所以这里我们还得做校准.</p>
<p>假设我们对负样本降采样, 使用 <code>$ \alpha n_&#123;-&#125;$</code> 个负样本, 其中 <code>$ \alpha \in (0, 1) $</code> 是采样率.</p>
<p>那么我们会有:</p>
<p><span class="math display">\[
真实点击率 p_{true} = \frac{n_{+}}{n_{+}+n_{-}}, 预估点击率 p_{pred} = \frac{n_{+}}{n_{+}+ \alpha \cdot n_{-}}\\
=&gt; p_{true} = \frac{\alpha \cdot p_{pred}}{(1-p_{pred}) + \alpha \cdot p_{pred}}
\]</span></p>
<h2 id="mmoemulti-gate-mixture-of-experts">MMoE(Multi-gate Mixture-of-Experts)</h2>
<p>说人话就是输入特征输出<strong>n个expert向量</strong>, 然后生成<strong>指标数量个权重</strong></p>
<p><img src="MMoE_first.png" /></p>
<p>这个图里面就是3个expert以及2个指标的例子,然后上层通过权重对expert做加权然后再丢进神经网络预测指标. expert数量是超参数, 需要调.</p>
<p><img src="MMoE_second.png" /></p>
<h3 id="存在问题">存在问题</h3>
<p><strong>polarize</strong>: softmax输出单值接近1, 而其他值接近0.</p>
<p>这种情况下可能某个指标的预测只用到了一个expert, 而其他的expert就没有派上用场.</p>
<p><strong>解决方案</strong>: 对softmax的输出用dropout, 如果发生了极化现象且dropout的值恰好为单值1, 那么模型的预测效果就会很差, 这样一来模型就会尽力避免极化.</p>
<h2 id="三塔模型">三塔模型</h2>
<p><img src="three_tower.png" /></p>
<p>其中用户塔和物品塔还是双塔模型里面的.</p>
<ul>
<li>用户塔可以很大, 反正只有算单用户向量, 线上实时计算.<br />
</li>
<li>物品塔可以较大, 因为物品塔向量大多数静态, 所以可以计算完毕之后直接离线存储, 需要的时候直接索引提取. 如果击中缓存直接提取, 没击中缓存实时计算.<br />
</li>
<li>交叉塔统计特征的动态变化, 不可以缓存; 一旦有n个物品就需要n次推理, 因此交叉塔需要尽量小.</li>
</ul>
<p>然后前面向量计算完了再做concatenation之后丢上层模型计算指标, 这里还是需要n次推理, 不过这里的n次推理计算量比交叉塔大(粗排推理大部分计算量在模型上层).</p>
<h2 id="fmfactorization-machine">FM(Factorization Machine)</h2>
<p>FM说白了就是对线性模型的x求二阶交叉并做简化.</p>
<p><strong>一阶线性</strong>: <code>$ p = b + \sum_&#123;i=1&#125;^d w_ix_i $</code></p>
<p><strong>二阶线性</strong>: <code>$ p = b + \sum_&#123;i=1&#125;^d w_ix_i + \sum_&#123;i=1&#125;^d\sum_&#123;j=i+1&#125;^d u_&#123;ij&#125;x_ix_j$</code></p>
<p>这里复杂度为 <code>$ O(d^2) $</code></p>
<p><strong>Factorization Machine</strong>: <code>$ p = b + \sum_&#123;i=1&#125;^d w_ix_i + \sum_&#123;i=1&#125;^d\sum_&#123;j=i+1&#125;^d (v_i^Tv_j)x_ix_j$</code></p>
<p>其实就是把 <code>$ u_&#123;ij&#125; $</code> 变成 <code>$ v_i^Tv_j $</code>, 即将权重矩阵分解为了两个小矩阵, 矩阵维度从 d * d 变成了 d * k.</p>
<p>然后这里作者其实少讲了一点, 就是FM模型其实是对稀疏特征有优化的, 假设x_i和x_j为稀疏特征, 那么交叉之后很多项都会是0, 权重u_ij就会变得非常难学习. 然而FM做了优化之后, 其实最终结果是从O(kn^2)化简成了O(kn). 这里直接贴图不用latex了.</p>
<p><img src="FM_optimized.png" /></p>
<p>可以发现最终其实j已经不见了, 其实就是每一个 <code>$ v_&#123;i,l&#125; $</code> 对应一个 <code>$ x_i $</code> . 即计算用的是一阶, 但是混合结果是二阶交叉, 即绕了个弯子: 既利用一阶特征学习到了权重, 又保证模型后面增加的是交叉项.</p>
<p>然后FM的好处就是一般涉及到特征交叉就可以用, 推荐场合效果显著. 不过现在也逐渐被淘汰了.</p>
<h2 id="dcn">DCN</h2>
<p>可以增加模型复杂度并提升模型性能, 其本身可以用在召回或者排序中的所有神经网络层里面. 交叉层公式如下:</p>
<p><span class="math display">\[
x_{i+1} = x_0 \odot (Wx_i + b) + x_0
\]</span></p>
<p>即每次用x_0和上一次的输出结果求hadamard product, 然后最后加上x_0防梯度消失.</p>
<p>交叉网络即多个交叉层连接</p>
<p><img src="Cross_Network.png" /></p>
<p>深度交叉网络则是在交叉网络的基础之上再加上全连网络.</p>
<p><img src="DCN.png" /></p>
<h2 id="lhuc">LHUC</h2>
<p>本身为语音识别里的技术, 希望可以让语音信号能够结合说话者的特征.</p>
<p><img src="voice_LHUC.png" /></p>
<p>模型本身对语音信号连接全连层,对说话者特征也是连接全连层并且最后加上一层sigmoid*2让输出在0-2之间, 从而对语音信号有的放大有的缩小.</p>
<p>如果使用两层那么就要用两个不同的神经网络负责说话者特征的处理, 然后依然是和语音信号求hadamard product. 最后输出.</p>
<p>推荐系统场合将语音信号换成物品特征, 说话者特征换成用户特征.</p>
<p><img src="Rank_LHUC.png" /></p>
<h2 id="加权和交叉">加权和交叉</h2>
<h3 id="senet">SENet</h3>
<p>本质是输入m * k矩阵, 对行取平均获得 m * 1 的向量, 然后对 m * 1 向量输入神经网络做升降维变换, 最后将输出的 m * 1向量作为权重矩阵对原 m * k矩阵求加权, 获得最终输出</p>
<p><img src="SENet.png" /></p>
<p><strong>注</strong>: SENet里面并不需求输入向量的维度相同, 因为是对行求pool然后再对对应行求加权, 最终维度和输入维度是相同的, 所以其实输入维度并没有影响.</p>
<h3 id="bilinear-cross">Bilinear Cross</h3>
<p>通常的特征交叉直接做内积或者hadamard乘积, 而bilinear cross是通过一个中间矩阵连接两边特征. 比如内积就会如下图, 从而生成输出.</p>
<p><img src="BilinearCross.png" /></p>
<p>输出大小是一回事, 但是参数矩阵是另外一回事, 有m个field就会产生m**2 / 2 个参数矩阵, 参数矩阵是参数爆炸点.</p>
<h3 id="fibinet">FiBiNet</h3>
<p>结合前面两者就是FiBiNet, 首先对embedding做concatenation获得一个向量, 然后对embedding做交叉然后concat获得另外一个向量, 对embedding做SENet加权然后再用bilinear cross获得最后的一个向量对这些做concatenation然后输入上层神经网络.</p>
<p>总结一下就是: 加权+ 交叉</p>
<p><img src="FiBiNet.png" /></p>
<h2 id="用户行为序列建模lastn特征">用户行为序列建模(LastN特征)</h2>
<p>我们取用户最后交互的n个物品id做embedding得到n个特征, 然后对特征取平均后输出一个向量, 即为用户最近交互物品的特征. 这个适用于双塔,三塔和其他粗排精排模型.</p>
<p><img src="LastN.png" /></p>
<h2 id="din模型对lastn的优化">DIN模型(对LastN的优化)</h2>
<p>上面的lastn我们看到取平均是很简单的一种方法, 我们可以使用更复杂的方式, 比如attention(加权平均)来获得更好的效果.</p>
<p>对于候选物品, 我们计算它和lastn的相似度, 然后以相似度为权重, 求用户lastn的物品做加权, 然后最后得到的向量就是一种新的用户特征, 输入排序模型之后再来预估点击率点赞率等.</p>
<p>(可以看成lastn为k,v; 候选物品为q的attention)</p>
<p>简单平均和attention都适用于精排, 但是对于双塔和三塔只能用简单平均. 这是因为注意力机制需要用到候选物品, 而用户塔会看不到候选物品, 从而并不能把注意力机制用在用户塔</p>
<p><img src="DIN.png" /></p>
<h2 id="sim模型">SIM模型</h2>
<p>大致原理和DIN相似,但是DIN存在问题:注意力的计算和LastN里面的N相关, 因此我们如果用了DIN, 那么N就不可以取太大的值. 因此阿里发了一篇论文, 即SIM, 其对于每个候选物品, 在用户的LastN里面做快速查找, 先找到与候选物品最相似的TopK, 由此来降低复杂度.</p>
<p>这样一来复杂度从N变成了K, 从而减小了计算量.</p>
<h3 id="search">Search</h3>
<p>主要分为hard search和soft search.</p>
<p>hard search指的是我们直接对LastN里面的物品类目进行筛选.</p>
<p>soft search指的是我们把物品做embedding, 然后用Knn来找最接近的k个物品. 这种方法效果更好, 但是更费资源且更难实现.</p>
<h3 id="attention部分">Attention部分</h3>
<p>这里需要注意, SIM对应的是大N, LastN大的话时间跨度也可能会很大, 因此我们需要使用时间信息来作为辅助数据.</p>
<ol type="1">
<li>我们将用户和某个物品交互的时刻记为 <code>$ \delta $</code><br />
</li>
<li>然后我们对 <code>$ \delta $</code> 做离散化, 再做embedding, 变成向量d.<br />
</li>
<li>我们将时间向量d和物品embedding的向量x做concatenation, 从而得到LastN物品的新表征</li>
</ol>
<p>其他部分就完全一致了</p>
<p><img src="SIM.png" /></p>
<p>总的来说就是:</p>
<ol type="1">
<li>长序列 &gt; 短序列<br />
</li>
<li>Attention &gt; 简单平均<br />
</li>
<li>SoftSearch &gt; Hard Search<br />
</li>
<li>使用时间信息对长序列有帮助</li>
</ol>
<h2 id="预估分数融合">预估分数融合</h2>
<p>前面的模型可以输出各种分数, 但是我们还需要对各种分数进行融合才能获取到最终的排序, 这里有很多不同的加权方式.</p>
<p><strong>最简单的直接加权</strong>: <code>$ p_&#123;click&#125; + w_1 \cdot p_&#123;like&#125; + w_2 \cdot p_&#123;collect&#125; ... $</code></p>
<p><strong>点击率乘其他加权</strong>: <code>$ p_&#123;click&#125; \cdot(1 + w_1 \cdot p_&#123;like&#125; + w_2 \cdot p_&#123;collect&#125; ... )$</code></p>
<p>这里 <code>$ p_&#123;click&#125; \cdot p_&#123;like&#125; $</code> 其实就是 <code>$ \frac&#123;n_&#123;点击数量&#125;&#125;&#123;n_&#123;曝光数量&#125;&#125; \cdot \frac&#123;n_&#123;点赞数量&#125;&#125;&#123;n_&#123;点击数量&#125;&#125; $</code> , 最终代表的就是曝光后点赞的数量.</p>
<p><strong>海外某短视频app的融分方式</strong>: <code>$ (1+w_1 \cdot p_&#123;time&#125;)^&#123;a_1&#125; \cdot (1+w_2 \cdot p_&#123;like&#125;)^&#123;a_2&#125; $</code></p>
<p><strong>国内某视频app的融分方式</strong>: 假设预估时长为 <code>$ p_&#123;time&#125; $</code>, 同时假设其排名为 <code>$ r_&#123;time&#125; $</code>, 那么其得分为 <code>$ \frac&#123;1&#125;&#123;r_&#123;time&#125;^&#123;a&#125; + b&#125; $</code></p>
<p>最终融合分数: <code>$ \frac&#123;1&#125;&#123;r_&#123;time&#125;^&#123;a_1&#125; + \beta_1&#125; + \frac&#123;1&#125;&#123;r_&#123;click&#125;^&#123;a_2&#125; + \beta_2&#125; + \frac&#123;1&#125;&#123;r_&#123;like&#125;^&#123;a_3&#125; + \beta_3&#125; + ...$</code></p>
<p><strong>国内某电商app的融分方式</strong>:</p>
<p>流程: 曝光, 点击, 加购物车, 付款.</p>
<p>模型估计: <code>$ p_&#123;click&#125; $</code>, <code>$ p_&#123;cart&#125; $</code>, <code>$ p_&#123;pay&#125; $</code></p>
<p>分数: <code>$ p_&#123;click&#125;^&#123;a_1&#125; \times p_&#123;cart&#125;^&#123;a_2&#125; \times p_&#123;pay&#125;^&#123;a_3&#125; \times price^&#123;a_4&#125;$</code></p>
<h2 id="视频播放建模">视频播放建模</h2>
<h3 id="时长">时长</h3>
<p>区别于图文, 视频类型还涉及到播放时长和完播率.</p>
<p>然而直接用regression建模播放时长效果并不好, youtube有一篇论文专门解决这个. 我并没有直接去看原论文,这里就只记录作者介绍的方法.</p>
<p><img src="视频建模.png" /></p>
<p>这里我们对输出做sigmoid然后对y_true也做1 / 1+y的处理.</p>
<p>训练的时候我们用交叉熵, 这样最后我们只需要对输出取exp(z)即可表示时长.</p>
<h3 id="完播">完播</h3>
<p>两种建模方式</p>
<p><strong>回归</strong>: 假设视频10分钟, 用户看了4分钟, 那么y=0.4. 我们通过预测播放率来拟合y, <code>$ loss = y \cdot logp + (1-y) \cdot log(1-p) $</code> .</p>
<p><strong>二分类</strong>: 比如我们将完播80%作为标准, 大于8分钟为正样本, 小于8分钟为负样本. 然后我们来预测模型为正样本的概率.</p>
<p>然而不管怎么样, 我们都不可以直接把输出的完播率用到融分公式. 因为视频的长度越长相对的完播率就会越低, 所以我们必须先用视频时长来拟合完播率, 最后再用预估完播率做调整.</p>
<p><span class="math display">\[
p_{finish} = \frac{预估完播率}{f视频长度}
\]</span></p>
<p>最后我们用 <code>$ p_&#123;finish&#125; $</code> 来加入融分公式.</p>
<h1 id="重排">重排</h1>
<p>多样性抽样: MRR, DPP</p>
<p>依据为精排分数以及内容多样性, 抽样之后规则打散, 搭配运营策略呈现.</p>
<h2 id="物品多样性问题">物品多样性问题</h2>
<p>简单来说就是我们希望最终得到的推荐物品应该是尽可能的多类别, 也即让物品尽可能得不相似. 那么首先就需要一个标准: 相似度怎么度量.</p>
<h3 id="相似度的度量">相似度的度量</h3>
<ol type="1">
<li>基于物品属性标签(类别, 品牌, 关键词等)<br />
</li>
<li>基于物品向量表征</li>
</ol>
<p>一般双塔模型学习到的物品向量效果都不太好; 与之对比, 基于内容的向量表征会有更好的效果(即NLP做文本处理, CV做图片处理)</p>
<p><strong>基于属性标签</strong>: 比如依据 一级类目, 二级类目, 品牌来计算相似度.</p>
<p>物品i: 美妆, 彩妆, 香奈儿<br />
物品j: 美妆, 香水, 香奈儿</p>
<p>这么一来, sim_1(i, j) = 1, sim_2(i, j) = 0, sim_3(i, j) = 1.</p>
<p><strong>基于物品向量</strong>:</p>
<p><strong>双塔模型</strong>: 由于物品的头部效应, 大部分点击物品都是热门物品, 而对于其他物品, 双塔模型并不能很好的学会它们的表征. 且如果使用物品塔计算的向量, 那么就很难处理新物品.</p>
<p><strong>基于内容的物品表征</strong>: 对于图片部分我们使用CNN, 对于文本部分我们可以使用bert等模型.</p>
<p>但是这里涉及一个难点, 如果使用外部训练过的模型, 那么直接迁移到业务范围效果就不太好, 但如果想用自己业务内数据, 那么又存在人工标注的问题.</p>
<p><strong>解决方案</strong>: CLIP, 具体的在新一篇博客里面已经讲过了, 其主要思想就是匹配的图文获得的score应该大于不匹配的图文, 使用对比的方式我们可以训练出预测图文是否匹配的模型. 其优势在于我们并不需要人工标注, 且小红书本来就包含不少图文数据, 直接丢模型训练就行</p>
<h3 id="提升多样性的方法">提升多样性的方法</h3>
<p>首先几亿物品经过召回变成几千, 粗排和精排阶段我们对物品做pointwise打分, 各个指标我们对其进行分数融合获得最终分数reward_i, 这个reward就是表示物品对用户的价值.</p>
<p>我们对n个候选物品打分, 获得n个reward.</p>
<p>最后我们对结果进行后处理, 要求物品不仅仅是总分高, 还必须要有多样性, 后面我们还会介绍多样性算法. 其中精排的后处理我们一般称为重排</p>
<p>注意, 不仅仅是精排, 粗排过后的打分也可以进行后处理的多样性处理, 而且能取得显著效果.</p>
<h2 id="maximal-marginal-relevancemmr">Maximal Marginal Relevance(MMR)</h2>
<p>精排对n个物品打分, 融合之后的分数为reward_1...reward_n, 然后我们记物品i和物品j的相似度为sim(i,j), 最终我们从n个物品选出k个, 要求不仅有高reward, 同时多样性也尽可能高.</p>
<p>假设选中的物品我们记为 <code>$ \delta $</code>, 未选中物品我们记为R</p>
<p><span class="math display">\[
MR_i = \theta \cdot reward_i - (1-\theta) \cdot max_{i \in S} sim(i,j)
\]</span></p>
<p>而MMR就是</p>
<p><span class="math display">\[
\mathop{\arg\max}\limits_{i \in R} MR_i
\]</span></p>
<ol type="1">
<li>我们初始化S为空集, R为全集<br />
</li>
<li>选精排分数最高的物品直接从R移到S<br />
</li>
<li>做k-1轮循环, 每轮计算R中所有物品分数 <code>$ \&#123;MR_i\&#125;_&#123;i \in R&#125; $</code><br />
</li>
<li>最后我们选出分数最高的物品, 从R移到S.</li>
</ol>
<p><strong>滑动窗口</strong>:</p>
<p>上述的MMR有个问题, 如果我们选中越多物品(S越大), 那么我们就越难找出一个物品 <code>$ i \in R $</code> 来使得i与S中物品都不相似, 即当S很大的时候, <code>$ max_&#123;j \in S&#125;sim(i, j) $</code>总会为1, 即S中总有元素和选出的元素有高相似度, 导致MMR算法失效.</p>
<p>解决方案就是滑动窗口, 我们取最后选出的某些物品作为滑动窗口W, 用W来代替MMR公式中的S, 即我们只考虑新加入集合的物品和最新取的某些物品的相似度而不是考虑整体相似度. 从而防止失效问题.</p>
<h2 id="dpp">DPP</h2>
<p>Determinantal point process(行列式点过程).</p>
<h3 id="超平行体">超平行体</h3>
<p>一组向量可以决定一个k维超平行体.</p>
<p>比如v1, v2可以决定一个平行四边形;v1, v2, v3可以决定一个平行六面体.</p>
<p>假设向量线性相关, 那么必定会导致的问题就是向量3落在向量12的平面内导致体积为0, 所以将超平行体的Volumn最大化的过程就是向量多样化的过程.</p>
<p>而超平行体的体积又可以表现为矩阵的行列式</p>
<p>给定k个物品, 向量表征为v1,v2...vk(dim为d,且d &gt;= k), 将其记为矩阵V</p>
<p><span class="math display">\[
det(V^TV) = vol(P(v_1, v_2,...v_k)) ^ 2
\]</span></p>
<p>因此,可以用矩阵的行列式来表示物品向量多样性.</p>
<h3 id="推荐系统">推荐系统</h3>
<p>Hulu的论文将dpp用在了推荐系统.</p>
<p><span class="math display">\[
\mathop{\arg\max}\limits_{S:\left|S \right|=k} \theta \cdot (\sum_{j \in S} reward_j) + (1-\theta) \cdot log (det(V^T_SV_S))
\]</span></p>
<p>其中可以用 $ A_s $ 来表示 $ V^T_SV_S $</p>
<p>而DPP是一个<strong>组合优化</strong>问题(从1-n中选出最优的k个元素), 且被认为是一个np hard问题, 只能近似求解.</p>
<p>每次选物品的时候, 我们去保证</p>
<p><span class="math display">\[
\mathop{\arg\max}\limits_{i \in R} \theta \cdot reward_j + (1-\theta) \cdot log (det(A_{S \cup \{i\}}))
\]</span></p>
<p>每次纳入一个新物品, 矩阵多了一行和一列, 我们希望加入一行一列的同时, 保证行列式尽量大.</p>
<p>暴力求解的情况, 计算行列式为O(S^3), 又因为物品有R个, 我们需要取出k个, 即O(S^3 * R * k) =&gt; O(nk^4), 而计算矩阵A还需要O(n^2 * d), 即最终复杂度为 $ O(n^2d + nk^4) $</p>
<p>Hulu的优化是能够利用O(nk^2)计算行列式的值(Cholesky分解).</p>
<p>Cholesky分解把矩阵A分成 $ A = LL^T $ , 其中L为下三角矩阵, 从而可以用对角线乘积表示行列式. 每次加入一行一列, 我们只需要算出相对原分解产生了哪些变化即可, 从而可以快速算出A_{S {i}}的分解.</p>
<p>后续滑动窗口还是和MRR一样</p>
<p>还有规则约束即改变取物品的集合R即可.</p>
<h2 id="重排的规则">重排的规则</h2>
<h3 id="最多连续出现k篇某种笔记">最多连续出现k篇某种笔记</h3>
<p>比如小红书会推荐图文笔记和视频笔记, 假设我们规定最多连续出现5篇图文笔记, 那么如果i到i+4都是图文笔记, 那么i+5必须是视频笔记</p>
<h3 id="每k篇笔记最多出现一篇某种笔记">每k篇笔记最多出现一篇某种笔记</h3>
<p>比如运营推广笔记, 我们会给精排分数乘以大于1的系数(boost)来帮助笔记获得曝光.</p>
<p>boost一般不是用户喜欢的, 出多了会影响用户体验, 所以我们为了限制boost, 限制每k=9篇笔记最多出现一篇运营推广笔记. 即如果i为运营推广笔记, 那么i+1到i+8就不能是运营推广笔记.</p>
<h3 id="前t篇笔记最多出现k篇某种笔记">前t篇笔记最多出现k篇某种笔记</h3>
<p>比如排面前t的物品最容易被看到, 对用户体验最重要(小红书top4为首屏).</p>
<p>而小红书推荐系统有电商卡片笔记, 过多可能会影响体验. 因此前t=1篇笔记最多出现k=0篇电商卡片, 前t=4篇笔记最多出现k=1篇电商卡片</p>
<h3 id="mr加规则">MR加规则</h3>
<p>MMR中我们每次从R中选出物品丢到S, 那么如果加上规则, 我们就可以先对R中物品进行规则过滤, 选出满足条件的集合R, 然后对过滤过的R做MMR.</p>

  </div>
</article>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
        
          <li><a href="/">Home</a></li>
        
          <li><a href="/about/">About</a></li>
        
          <li><a href="/archives/">Writing</a></li>
        
          <li><a href="/categories/">Category</a></li>
        
          <li><a href="/search/">Search</a></li>
        
      </ul>
    </div>

    
    
      <div id="toc-footer" style="display: none">
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%B2%97%E6%8E%92%E5%92%8C%E7%B2%BE%E6%8E%92"><span class="toc-number">1.</span> <span class="toc-text">粗排和精排</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E6%95%B0%E6%8D%AE"><span class="toc-number">1.1.</span> <span class="toc-text">特征数据</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#profile"><span class="toc-number">1.1.1.</span> <span class="toc-text">Profile</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#user-profile"><span class="toc-number">1.1.1.1.</span> <span class="toc-text">User Profile</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#item-profile"><span class="toc-number">1.1.1.2.</span> <span class="toc-text">Item Profile</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%9F%E8%AE%A1%E7%89%B9%E5%BE%81"><span class="toc-number">1.1.2.</span> <span class="toc-text">统计特征</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%94%A8%E6%88%B7%E7%BB%9F%E8%AE%A1%E7%89%B9%E5%BE%81"><span class="toc-number">1.1.2.1.</span> <span class="toc-text">用户统计特征</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AC%94%E8%AE%B0%E7%89%A9%E5%93%81%E7%BB%9F%E8%AE%A1%E7%89%B9%E5%BE%81"><span class="toc-number">1.1.2.2.</span> <span class="toc-text">笔记(物品)统计特征</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF%E7%89%B9%E5%BE%81context"><span class="toc-number">1.1.3.</span> <span class="toc-text">场景特征(context)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E5%A4%84%E7%90%86"><span class="toc-number">1.1.4.</span> <span class="toc-text">特征处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B4%E4%BD%93%E6%B5%81%E7%A8%8B"><span class="toc-number">1.1.5.</span> <span class="toc-text">整体流程</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E7%9B%AE%E6%A0%87%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.2.</span> <span class="toc-text">多目标模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E7%BB%86%E8%8A%82"><span class="toc-number">1.2.1.</span> <span class="toc-text">模型细节</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">1.2.2.</span> <span class="toc-text">损失函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E7%9A%84%E5%9B%B0%E9%9A%BE-%E7%B1%BB%E5%88%AB%E4%B8%8D%E5%B9%B3%E8%A1%A1"><span class="toc-number">1.2.3.</span> <span class="toc-text">训练的困难-类别不平衡</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%99%8D%E9%87%87%E6%A0%B7%E6%A0%A1%E5%87%86"><span class="toc-number">1.2.4.</span> <span class="toc-text">降采样校准</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#mmoemulti-gate-mixture-of-experts"><span class="toc-number">1.3.</span> <span class="toc-text">MMoE(Multi-gate Mixture-of-Experts)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AD%98%E5%9C%A8%E9%97%AE%E9%A2%98"><span class="toc-number">1.3.1.</span> <span class="toc-text">存在问题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E5%A1%94%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.4.</span> <span class="toc-text">三塔模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#fmfactorization-machine"><span class="toc-number">1.5.</span> <span class="toc-text">FM(Factorization Machine)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#dcn"><span class="toc-number">1.6.</span> <span class="toc-text">DCN</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#lhuc"><span class="toc-number">1.7.</span> <span class="toc-text">LHUC</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8A%A0%E6%9D%83%E5%92%8C%E4%BA%A4%E5%8F%89"><span class="toc-number">1.8.</span> <span class="toc-text">加权和交叉</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#senet"><span class="toc-number">1.8.1.</span> <span class="toc-text">SENet</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#bilinear-cross"><span class="toc-number">1.8.2.</span> <span class="toc-text">Bilinear Cross</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#fibinet"><span class="toc-number">1.8.3.</span> <span class="toc-text">FiBiNet</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E5%BA%8F%E5%88%97%E5%BB%BA%E6%A8%A1lastn%E7%89%B9%E5%BE%81"><span class="toc-number">1.9.</span> <span class="toc-text">用户行为序列建模(LastN特征)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#din%E6%A8%A1%E5%9E%8B%E5%AF%B9lastn%E7%9A%84%E4%BC%98%E5%8C%96"><span class="toc-number">1.10.</span> <span class="toc-text">DIN模型(对LastN的优化)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#sim%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.11.</span> <span class="toc-text">SIM模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#search"><span class="toc-number">1.11.1.</span> <span class="toc-text">Search</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#attention%E9%83%A8%E5%88%86"><span class="toc-number">1.11.2.</span> <span class="toc-text">Attention部分</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A2%84%E4%BC%B0%E5%88%86%E6%95%B0%E8%9E%8D%E5%90%88"><span class="toc-number">1.12.</span> <span class="toc-text">预估分数融合</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%86%E9%A2%91%E6%92%AD%E6%94%BE%E5%BB%BA%E6%A8%A1"><span class="toc-number">1.13.</span> <span class="toc-text">视频播放建模</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%B6%E9%95%BF"><span class="toc-number">1.13.1.</span> <span class="toc-text">时长</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%8C%E6%92%AD"><span class="toc-number">1.13.2.</span> <span class="toc-text">完播</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%87%8D%E6%8E%92"><span class="toc-number">2.</span> <span class="toc-text">重排</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%89%A9%E5%93%81%E5%A4%9A%E6%A0%B7%E6%80%A7%E9%97%AE%E9%A2%98"><span class="toc-number">2.1.</span> <span class="toc-text">物品多样性问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%B8%E4%BC%BC%E5%BA%A6%E7%9A%84%E5%BA%A6%E9%87%8F"><span class="toc-number">2.1.1.</span> <span class="toc-text">相似度的度量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8F%90%E5%8D%87%E5%A4%9A%E6%A0%B7%E6%80%A7%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-number">2.1.2.</span> <span class="toc-text">提升多样性的方法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#maximal-marginal-relevancemmr"><span class="toc-number">2.2.</span> <span class="toc-text">Maximal Marginal Relevance(MMR)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#dpp"><span class="toc-number">2.3.</span> <span class="toc-text">DPP</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B6%85%E5%B9%B3%E8%A1%8C%E4%BD%93"><span class="toc-number">2.3.1.</span> <span class="toc-text">超平行体</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F"><span class="toc-number">2.3.2.</span> <span class="toc-text">推荐系统</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%87%8D%E6%8E%92%E7%9A%84%E8%A7%84%E5%88%99"><span class="toc-number">2.4.</span> <span class="toc-text">重排的规则</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%80%E5%A4%9A%E8%BF%9E%E7%BB%AD%E5%87%BA%E7%8E%B0k%E7%AF%87%E6%9F%90%E7%A7%8D%E7%AC%94%E8%AE%B0"><span class="toc-number">2.4.1.</span> <span class="toc-text">最多连续出现k篇某种笔记</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AF%8Fk%E7%AF%87%E7%AC%94%E8%AE%B0%E6%9C%80%E5%A4%9A%E5%87%BA%E7%8E%B0%E4%B8%80%E7%AF%87%E6%9F%90%E7%A7%8D%E7%AC%94%E8%AE%B0"><span class="toc-number">2.4.2.</span> <span class="toc-text">每k篇笔记最多出现一篇某种笔记</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%89%8Dt%E7%AF%87%E7%AC%94%E8%AE%B0%E6%9C%80%E5%A4%9A%E5%87%BA%E7%8E%B0k%E7%AF%87%E6%9F%90%E7%A7%8D%E7%AC%94%E8%AE%B0"><span class="toc-number">2.4.3.</span> <span class="toc-text">前t篇笔记最多出现k篇某种笔记</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#mr%E5%8A%A0%E8%A7%84%E5%88%99"><span class="toc-number">2.4.4.</span> <span class="toc-text">MR加规则</span></a></li></ol></li></ol></li></ol>
      </div>
    

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/&text=工业化推荐系统相关(2)-粗排精排"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/&title=工业化推荐系统相关(2)-粗排精排"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/&is_video=false&description=工业化推荐系统相关(2)-粗排精排"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=工业化推荐系统相关(2)-粗排精排&body=Check out this article: http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/"><i class="fa-solid fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/&title=工业化推荐系统相关(2)-粗排精排"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/&title=工业化推荐系统相关(2)-粗排精排"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/&title=工业化推荐系统相关(2)-粗排精排"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/&title=工业化推荐系统相关(2)-粗排精排"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/&name=工业化推荐系统相关(2)-粗排精排&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://example.com/2024/05/17/%E5%B7%A5%E4%B8%9A%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3-2-%E7%B2%97%E6%8E%92%E7%B2%BE%E6%8E%92/&t=工业化推荐系统相关(2)-粗排精排"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fa-solid fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        
          <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fa-solid fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fa-solid fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2016-2024
    blacsheep
  </div>
  <div class="footer-right">
    <nav>
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     --><!--
       --><li><a href="/categories/">Category</a></li><!--
     --><!--
       --><li><a href="/search/">Search</a></li><!--
     -->
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->



  <link rel="preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" crossorigin="anonymous" onload="this.onload=null;this.rel='stylesheet'"/>


    <!-- jquery -->

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" crossorigin="anonymous"></script>




<!-- clipboard -->

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.7/clipboard.min.js" crossorigin="anonymous"></script>
  
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="fa-regular fa-clone"></i>';
    btn += '</span>';
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Baidu Analytics -->

<!-- Cloudflare Analytics -->

<!-- Disqus Comments -->

<!-- utterances Comments -->

</body>
</html>
